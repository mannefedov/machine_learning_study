{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting dask\n",
      "  Downloading dask-2022.2.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 50.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas) (1.22.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.7 MB 57.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from dask) (21.3)\n",
      "Collecting partd>=0.3.10\n",
      "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
      "Collecting cloudpickle>=1.1.1\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Collecting pyyaml>=5.3.1\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[K     |████████████████████████████████| 701 kB 52.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec>=0.6.0\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 65.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting toolz>=0.8.2\n",
      "  Downloading toolz-0.11.2-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 5.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 54.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.1.0\n",
      "  Downloading scipy-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 41.6 MB 57.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->dask) (3.0.7)\n",
      "Collecting locket\n",
      "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1308 sha256=5f527b06e07328eac75e18a3911b01b7bf1725a30fa147c7852f922011cbf189\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: pandas, threadpoolctl, joblib, scipy, scikit-learn, sklearn, toolz, locket, partd, cloudpickle, pyyaml, fsspec, dask\n",
      "Successfully installed cloudpickle-2.0.0 dask-2022.2.0 fsspec-2022.1.0 joblib-1.1.0 locket-0.2.1 pandas-1.4.1 partd-1.2.0 pyyaml-6.0 scikit-learn-1.0.2 scipy-1.8.0 sklearn-0.0 threadpoolctl-3.1.0 toolz-0.11.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas sklearn dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-4.2.1.tar.gz (13 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.4.2-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.14.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests[socks] in /usr/lib/python3/dist-packages (from gdown) (2.22.0)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.2.1-py3-none-any.whl size=14429 sha256=6c0ddcc1d92be503eb179cf0fdcca7a7914d54ffa27658f176c3772bcdc8f2bb\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/0c/4a/58330447f4c918159f819cd72e1fe7d4d2832585a164929f18\n",
      "Successfully built gdown\n",
      "Installing collected packages: filelock, tqdm, soupsieve, beautifulsoup4, gdown, PySocks\n",
      "Successfully installed PySocks-1.7.1 beautifulsoup4-4.10.0 filelock-3.4.2 gdown-4.2.1 soupsieve-2.3.1 tqdm-4.62.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1TkwQqEbkUspNhHz9_OQrad8-QRLm30rt\n",
      "To: /root/transactions_train.csv.zip\n",
      "100%|████████████████████████████████████████| 613M/613M [00:07<00:00, 85.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1TkwQqEbkUspNhHz9_OQrad8-QRLm30rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  transactions_train.csv.zip\n",
      "  inflating: transactions_train.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip transactions_train.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  articles.csv.zip\n",
      "  inflating: articles.csv            \n"
     ]
    }
   ],
   "source": [
    "!unzip articles.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  sample_submission.csv.zip\n",
      "  inflating: sample_submission.csv   \n"
     ]
    }
   ],
   "source": [
    "!unzip sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  customers.csv.zip\n",
      "  inflating: customers.csv           \n"
     ]
    }
   ],
   "source": [
    "!unzip customers.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:30:21.502390Z",
     "iopub.status.busy": "2022-02-13T07:30:21.499828Z",
     "iopub.status.idle": "2022-02-13T07:30:24.372815Z",
     "shell.execute_reply": "2022-02-13T07:30:24.372079Z",
     "shell.execute_reply.started": "2022-02-13T07:30:21.502304Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import dask.dataframe as dd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:30:24.376849Z",
     "iopub.status.busy": "2022-02-13T07:30:24.376319Z",
     "iopub.status.idle": "2022-02-13T07:30:28.077881Z",
     "shell.execute_reply": "2022-02-13T07:30:28.077164Z",
     "shell.execute_reply.started": "2022-02-13T07:30:24.376813Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:30:28.081285Z",
     "iopub.status.busy": "2022-02-13T07:30:28.081081Z",
     "iopub.status.idle": "2022-02-13T07:30:28.087741Z",
     "shell.execute_reply": "2022-02-13T07:30:28.086930Z",
     "shell.execute_reply.started": "2022-02-13T07:30:28.081261Z"
    }
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:30:28.090436Z",
     "iopub.status.busy": "2022-02-13T07:30:28.089695Z",
     "iopub.status.idle": "2022-02-13T07:30:28.134749Z",
     "shell.execute_reply": "2022-02-13T07:30:28.134135Z",
     "shell.execute_reply.started": "2022-02-13T07:30:28.090399Z"
    }
   },
   "outputs": [],
   "source": [
    "transactions = dd.read_csv(\n",
    "    'transactions_train.csv',\n",
    "    # set dtype or pandas will drop the leading '0' and convert to int\n",
    "    dtype={'article_id': str,\n",
    "#           't_dat': str,\n",
    "#            'customer_id':str, \n",
    "#           'price':float,\n",
    "#           'sales_channel_id': 'object'\n",
    "          } \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:30:28.137906Z",
     "iopub.status.busy": "2022-02-13T07:30:28.137724Z",
     "iopub.status.idle": "2022-02-13T07:30:28.180036Z",
     "shell.execute_reply": "2022-02-13T07:30:28.179383Z",
     "shell.execute_reply.started": "2022-02-13T07:30:28.137882Z"
    }
   },
   "outputs": [],
   "source": [
    "customers = dd.read_csv('customers.csv', dtype={'customer_id':str, \n",
    "#                                                                                                       'FN':int, \n",
    "#                                                                                                         'Active':int, \n",
    "#                                                                                                       'club_member_status':int,\n",
    "#                                                                                                         'fashion_news_frequency':str, \n",
    "#                                                                                                       'age':float, \n",
    "#                                                                                                         'postal_code':str\n",
    "                                                                                                     })\n",
    "articles = dd.read_csv('articles.csv', dtype={'article_id':str, \n",
    "#                                                                                                     'product_code':int, 'prod_name':str, \n",
    "#                                                                                                       'product_type_no':'object',\n",
    "#                                                                        'product_type_name':str, 'product_group_name':'object', 'graphical_appearance_no':'object',\n",
    "#                                                                        'graphical_appearance_name':str, 'colour_group_code':'object', 'colour_group_name':str,\n",
    "#                                                                        'perceived_colour_value_id':str, 'perceived_colour_value_name':str,\n",
    "#                                                                        'perceived_colour_master_id':str, 'perceived_colour_master_name':str,\n",
    "#                                                                        'department_no':int, 'department_name':str, 'index_code':str, 'index_name':str,\n",
    "#                                                                        'index_group_no':'object', 'index_group_name':str, 'section_no':int, 'section_name':str,\n",
    "#                                                                        'garment_group_no':'object', 'garment_group_name':str, 'detail_desc':str\n",
    "                                                                                                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:30:28.181432Z",
     "iopub.status.busy": "2022-02-13T07:30:28.181211Z",
     "iopub.status.idle": "2022-02-13T07:30:32.407764Z",
     "shell.execute_reply": "2022-02-13T07:30:32.407018Z",
     "shell.execute_reply.started": "2022-02-13T07:30:28.181399Z"
    }
   },
   "outputs": [],
   "source": [
    "customers = customers[['customer_id', 'age', 'postal_code']].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:30:32.409288Z",
     "iopub.status.busy": "2022-02-13T07:30:32.409055Z",
     "iopub.status.idle": "2022-02-13T07:30:32.426896Z",
     "shell.execute_reply": "2022-02-13T07:30:32.426228Z",
     "shell.execute_reply.started": "2022-02-13T07:30:32.409258Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_age = round(customers.age.dropna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:30:32.428631Z",
     "iopub.status.busy": "2022-02-13T07:30:32.428148Z",
     "iopub.status.idle": "2022-02-13T07:30:38.029866Z",
     "shell.execute_reply": "2022-02-13T07:30:38.029012Z",
     "shell.execute_reply.started": "2022-02-13T07:30:32.428592Z"
    }
   },
   "outputs": [],
   "source": [
    "cust2age = {}\n",
    "cust2postal = {}\n",
    "for c, a in customers[['customer_id', 'age']].fillna(mean_age).values:\n",
    "    cust2age[c] = a\n",
    "\n",
    "for c, p in customers[['customer_id', 'postal_code']].dropna().values:\n",
    "    cust2postal[c] = p  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:30:38.031409Z",
     "iopub.status.busy": "2022-02-13T07:30:38.031159Z",
     "iopub.status.idle": "2022-02-13T07:30:38.041010Z",
     "shell.execute_reply": "2022-02-13T07:30:38.040296Z",
     "shell.execute_reply.started": "2022-02-13T07:30:38.031376Z"
    }
   },
   "outputs": [],
   "source": [
    "transactions_train = transactions[(transactions['t_dat'] < '2020-09-15') & (transactions['t_dat'] > '2018-09-15')]\n",
    "transactions_test = transactions[transactions['t_dat'] > '2020-09-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:30:38.044115Z",
     "iopub.status.busy": "2022-02-13T07:30:38.043359Z",
     "iopub.status.idle": "2022-02-13T07:30:38.079743Z",
     "shell.execute_reply": "2022-02-13T07:30:38.079054Z",
     "shell.execute_reply.started": "2022-02-13T07:30:38.044074Z"
    }
   },
   "outputs": [],
   "source": [
    "transactions_train_arts = dd.merge(transactions_train, articles[['article_id','prod_name']], \n",
    "                                   on='article_id', how='left')\n",
    "transactions_test_arts = dd.merge(transactions_test, articles[['article_id','prod_name']],\n",
    "                                  on='article_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:30:38.081815Z",
     "iopub.status.busy": "2022-02-13T07:30:38.081383Z",
     "iopub.status.idle": "2022-02-13T07:33:11.603448Z",
     "shell.execute_reply": "2022-02-13T07:33:11.602688Z",
     "shell.execute_reply.started": "2022-02-13T07:30:38.081775Z"
    }
   },
   "outputs": [],
   "source": [
    "transactions_train_arts = transactions_train_arts.compute()\n",
    "transactions_test_arts = transactions_test_arts.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T12:12:39.899149Z",
     "iopub.status.busy": "2022-02-13T12:12:39.898869Z",
     "iopub.status.idle": "2022-02-13T12:12:39.916851Z",
     "shell.execute_reply": "2022-02-13T12:12:39.915969Z",
     "shell.execute_reply.started": "2022-02-13T12:12:39.899117Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten(lists):\n",
    "    r = []\n",
    "    for l in lists:\n",
    "        for el in l:\n",
    "            r.append(el)\n",
    "    return r\n",
    "\n",
    "def preprocess_dataset(filename, df, cust2age, cust2postal, max_steps=10000):\n",
    "\n",
    "    f = open(filename, 'w')\n",
    "    \n",
    "    grouped = df.groupby('customer_id')\n",
    "    keys = set(grouped.groups)\n",
    "\n",
    "    for jj, key in enumerate(keys):\n",
    "        if jj > max_steps:\n",
    "            break\n",
    "        age = cust2age[key]\n",
    "        postcode = cust2postal[key]\n",
    "        history_dates_steps = grouped.get_group(key).groupby('t_dat')['prod_name'].agg(list).reset_index()\n",
    "        history_steps = history_dates_steps['prod_name'].values.tolist()\n",
    "        dates_steps = history_dates_steps['t_dat'].apply(lambda x: int(x.split('-')[1])).values.tolist()\n",
    "#         history_steps_articles = grouped.get_group(key).groupby('t_dat')['article_id'].agg(list).values.tolist()[-50:]\n",
    "\n",
    "        for i in range(len(history_steps)):\n",
    "#             if np.random.choice([1,0]):\n",
    "#                 continue\n",
    "            current_history = '##'.join(flatten(history_steps[:i])).replace('\\t', ' ')\n",
    "            f.write('\\t'.join([str(round(age)), \n",
    "                               postcode, \n",
    "                               current_history, \n",
    "                               '##'.join(history_steps[i]),\n",
    "                               str(dates_steps[i]),\n",
    "                               key]) + '\\n')\n",
    "\n",
    "    f.close()\n",
    "\n",
    "def preprocess_for_inference(filename, df, cust2age, cust2postal):\n",
    "    f = open(filename, 'w')\n",
    "    \n",
    "\n",
    "    for key, target, history, dat in df[['customer_id', 'prod_name', 'prod_name_history', 't_dat']].fillna(' ').values:\n",
    "        age = cust2age[key]\n",
    "        postcode = cust2postal[key]\n",
    "\n",
    "        history = '##'.join(history.replace('\\t', ' ').split('##'))\n",
    "        f.write('\\t'.join([str(round(age)), postcode, history, target, str(dat), key]) + '\\n')\n",
    "\n",
    "    f.close()\n",
    "\n",
    "def preprocess_for_submission(filename, df, cust2age, cust2postal):\n",
    "    f = open(filename, 'w')\n",
    "    \n",
    "\n",
    "    for key, history in df[['customer_id', 'prod_name']].fillna(' ').values:\n",
    "        age = cust2age[key]\n",
    "        postcode = cust2postal[key]\n",
    "\n",
    "        history = '##'.join(history.replace('\\t', ' ').split('##')[-50:])\n",
    "        f.write('\\t'.join([str(round(age)), postcode, history, ' ', '9', key]) + '\\n')\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = transactions_test_arts.groupby('customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped['t_dat'].agg('nunique').sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups = set(grouped.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates = grouped.get_group('76708d589a34d051205e42ce8db8da20aeb5f3954c395da7b76bb0db11fc648b') \\\n",
    "#                             .groupby('t_dat')['prod_name'] \\\n",
    "#                             .agg(list).reset_index()['t_dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_train_arts.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_cid, valid_df_cid = train_test_split(transactions_train_arts.customer_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T13:41:12.143597Z",
     "iopub.status.busy": "2022-02-13T13:41:12.143322Z",
     "iopub.status.idle": "2022-02-13T13:51:54.123256Z",
     "shell.execute_reply": "2022-02-13T13:51:54.122515Z",
     "shell.execute_reply.started": "2022-02-13T13:41:12.143568Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_dataset('train_dataset.csv', \n",
    "                   transactions_train_arts[transactions_train_arts.customer_id.isin(train_df_cid)], cust2age, \n",
    "                   cust2postal, max_steps=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:57:14.991614Z",
     "iopub.status.busy": "2022-02-13T09:57:14.990859Z",
     "iopub.status.idle": "2022-02-13T09:57:25.304869Z",
     "shell.execute_reply": "2022-02-13T09:57:25.304117Z",
     "shell.execute_reply.started": "2022-02-13T09:57:14.991549Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_dataset('test_dataset.csv', \n",
    "                   transactions_train_arts[transactions_train_arts.customer_id.isin(valid_df_cid)], \n",
    "                   cust2age, cust2postal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T12:10:14.583508Z",
     "iopub.status.busy": "2022-02-13T12:10:14.583250Z",
     "iopub.status.idle": "2022-02-13T12:10:33.425843Z",
     "shell.execute_reply": "2022-02-13T12:10:33.425025Z",
     "shell.execute_reply.started": "2022-02-13T12:10:14.583480Z"
    }
   },
   "outputs": [],
   "source": [
    "infer_df = transactions_test_arts.groupby('customer_id')[['prod_name', 't_dat']] \\\n",
    ".agg({'prod_name':'##'.join, 't_dat':lambda x: list(x)[0]}) \\\n",
    ".join(\n",
    "    transactions_train_arts.groupby('customer_id')['prod_name'].agg('##'.join), how='left', rsuffix='_history'\n",
    "                                                                                 ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T12:10:33.427789Z",
     "iopub.status.busy": "2022-02-13T12:10:33.427512Z",
     "iopub.status.idle": "2022-02-13T12:10:33.442368Z",
     "shell.execute_reply": "2022-02-13T12:10:33.441457Z",
     "shell.execute_reply.started": "2022-02-13T12:10:33.427754Z"
    }
   },
   "outputs": [],
   "source": [
    "infer_df['t_dat'] = infer_df['t_dat'].apply(lambda x: int(x.split('-')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T12:12:46.639953Z",
     "iopub.status.busy": "2022-02-13T12:12:46.639701Z",
     "iopub.status.idle": "2022-02-13T12:12:47.321910Z",
     "shell.execute_reply": "2022-02-13T12:12:47.320903Z",
     "shell.execute_reply.started": "2022-02-13T12:12:46.639924Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_for_inference('infer_df_valid_dataset.csv', infer_df, cust2age, cust2postal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:37:39.402994Z",
     "iopub.status.busy": "2022-02-13T07:37:39.402752Z",
     "iopub.status.idle": "2022-02-13T07:37:43.275320Z",
     "shell.execute_reply": "2022-02-13T07:37:43.274503Z",
     "shell.execute_reply.started": "2022-02-13T07:37:39.402960Z"
    }
   },
   "outputs": [],
   "source": [
    "# submussion_df = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:37:43.276963Z",
     "iopub.status.busy": "2022-02-13T07:37:43.276725Z",
     "iopub.status.idle": "2022-02-13T07:38:00.824209Z",
     "shell.execute_reply": "2022-02-13T07:38:00.823482Z",
     "shell.execute_reply.started": "2022-02-13T07:37:43.276931Z"
    }
   },
   "outputs": [],
   "source": [
    "# submision_df = submussion_df.join(transactions_train_arts.groupby('customer_id')['prod_name'].agg('##'.join), on='customer_id', how='left', \n",
    "                                                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:38:00.825931Z",
     "iopub.status.busy": "2022-02-13T07:38:00.825680Z",
     "iopub.status.idle": "2022-02-13T07:38:09.577972Z",
     "shell.execute_reply": "2022-02-13T07:38:09.577252Z",
     "shell.execute_reply.started": "2022-02-13T07:38:00.825897Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess_for_submission('submission_dataset.csv', submision_df, cust2age, cust2postal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T12:13:16.099150Z",
     "iopub.status.busy": "2022-02-13T12:13:16.098610Z",
     "iopub.status.idle": "2022-02-13T12:13:16.672402Z",
     "shell.execute_reply": "2022-02-13T12:13:16.671433Z",
     "shell.execute_reply.started": "2022-02-13T12:13:16.099111Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('train_dataset.csv', sep='\\t', header=None, names=['age', 'post', 'history', 'target'])\n",
    "dataset_test = pd.read_csv('test_dataset.csv', sep='\\t', header=None, names=['age', 'post', 'history', 'target', \n",
    "                                                                             't_dat','customer_id'])\n",
    "valid_dataset = pd.read_csv('infer_df_valid_dataset.csv', sep='\\t', header=None, names=['age', 'post', 'history', \n",
    "                                                                                        'target', 't_dat', 'customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>post</th>\n",
       "      <th>history</th>\n",
       "      <th>target</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2e477694b63ada8920e647fe222780b22c8d8c0788c3a8...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chestnut strap top##Dame##Rodin##TILLY BLOUSE#...</td>\n",
       "      <td>4</td>\n",
       "      <td>7af3b232b25d4b7960e4b817aa756bf10b93e6e513c264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>d0ecb24786dac0cdcc957cafbb5bd5151793eb27f4e106...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TP THEO hoodie BB##TP THEO hoodie BB</td>\n",
       "      <td>10</td>\n",
       "      <td>491ff1894b96bfa2e827519917d413fe44fb06e7446c8e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>d0ecb24786dac0cdcc957cafbb5bd5151793eb27f4e106...</td>\n",
       "      <td>TP THEO hoodie BB##TP THEO hoodie BB</td>\n",
       "      <td>Mister Muscle LS##CA Gustavsberg TVP</td>\n",
       "      <td>4</td>\n",
       "      <td>491ff1894b96bfa2e827519917d413fe44fb06e7446c8e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>24b5423a918bd5269176fe85e311554a4df5d838c16c3e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tiblisi paperwaist tapered##KELLY SHIRT##KELLY...</td>\n",
       "      <td>5</td>\n",
       "      <td>53262b1e8d0bc2a29f5e92915de90c64129ec9ae06fb83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>6c63be0de195adafd7065873c88fdf78081191aa529fe7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ED Madison Skinny HW##Skinny RW denim##ED Desp...</td>\n",
       "      <td>10</td>\n",
       "      <td>fb160bc5168dd942886289b772987a28ca28ad687e1f92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65692</th>\n",
       "      <td>50</td>\n",
       "      <td>0d3ef8cd70bd193de99456e9b50984f10268ae1e5edc87...</td>\n",
       "      <td>W YODA KNIT OL OFFER##Pablo coat##Angel Hoodie...</td>\n",
       "      <td>Wake rib polo</td>\n",
       "      <td>12</td>\n",
       "      <td>b0fab595b692dfe7bb2d2df0fe600ad862dc9c3d7c8b9c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65693</th>\n",
       "      <td>17</td>\n",
       "      <td>33d40124ebc670caa116f1b2395a31f799c1835205eb87...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tilda tank##Tilda tank##Ghost LS</td>\n",
       "      <td>3</td>\n",
       "      <td>ffe6d70abd5cbb9ace0630da24f6224b4925f3fd6b90b9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65694</th>\n",
       "      <td>21</td>\n",
       "      <td>f94a369132c077f64448855fe9bac7dc4c9c2f4d79c8d9...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pablo sweatshirt</td>\n",
       "      <td>12</td>\n",
       "      <td>c406e0ff833aaf745bf565970a81d1e779c8fabfdac380...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65695</th>\n",
       "      <td>21</td>\n",
       "      <td>f94a369132c077f64448855fe9bac7dc4c9c2f4d79c8d9...</td>\n",
       "      <td>Pablo sweatshirt</td>\n",
       "      <td>Hazelnut Push Melbourne##Pilar high support</td>\n",
       "      <td>5</td>\n",
       "      <td>c406e0ff833aaf745bf565970a81d1e779c8fabfdac380...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65696</th>\n",
       "      <td>19</td>\n",
       "      <td>914d338339bd06443a79acfa6548af3c04ea2ec1cbde0c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jade Denim Petite Trs 1</td>\n",
       "      <td>9</td>\n",
       "      <td>e9ad9cb8960378a638ab6924ba52672f361acb27909d0e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65697 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                                               post  \\\n",
       "0       22  2e477694b63ada8920e647fe222780b22c8d8c0788c3a8...   \n",
       "1       52  d0ecb24786dac0cdcc957cafbb5bd5151793eb27f4e106...   \n",
       "2       52  d0ecb24786dac0cdcc957cafbb5bd5151793eb27f4e106...   \n",
       "3       42  24b5423a918bd5269176fe85e311554a4df5d838c16c3e...   \n",
       "4       25  6c63be0de195adafd7065873c88fdf78081191aa529fe7...   \n",
       "...    ...                                                ...   \n",
       "65692   50  0d3ef8cd70bd193de99456e9b50984f10268ae1e5edc87...   \n",
       "65693   17  33d40124ebc670caa116f1b2395a31f799c1835205eb87...   \n",
       "65694   21  f94a369132c077f64448855fe9bac7dc4c9c2f4d79c8d9...   \n",
       "65695   21  f94a369132c077f64448855fe9bac7dc4c9c2f4d79c8d9...   \n",
       "65696   19  914d338339bd06443a79acfa6548af3c04ea2ec1cbde0c...   \n",
       "\n",
       "                                                 history  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                   TP THEO hoodie BB##TP THEO hoodie BB   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "65692  W YODA KNIT OL OFFER##Pablo coat##Angel Hoodie...   \n",
       "65693                                                NaN   \n",
       "65694                                                NaN   \n",
       "65695                                   Pablo sweatshirt   \n",
       "65696                                                NaN   \n",
       "\n",
       "                                                  target  t_dat  \\\n",
       "0      Chestnut strap top##Dame##Rodin##TILLY BLOUSE#...      4   \n",
       "1                   TP THEO hoodie BB##TP THEO hoodie BB     10   \n",
       "2                   Mister Muscle LS##CA Gustavsberg TVP      4   \n",
       "3      Tiblisi paperwaist tapered##KELLY SHIRT##KELLY...      5   \n",
       "4      ED Madison Skinny HW##Skinny RW denim##ED Desp...     10   \n",
       "...                                                  ...    ...   \n",
       "65692                                      Wake rib polo     12   \n",
       "65693                   Tilda tank##Tilda tank##Ghost LS      3   \n",
       "65694                                   Pablo sweatshirt     12   \n",
       "65695        Hazelnut Push Melbourne##Pilar high support      5   \n",
       "65696                            Jade Denim Petite Trs 1      9   \n",
       "\n",
       "                                             customer_id  \n",
       "0      7af3b232b25d4b7960e4b817aa756bf10b93e6e513c264...  \n",
       "1      491ff1894b96bfa2e827519917d413fe44fb06e7446c8e...  \n",
       "2      491ff1894b96bfa2e827519917d413fe44fb06e7446c8e...  \n",
       "3      53262b1e8d0bc2a29f5e92915de90c64129ec9ae06fb83...  \n",
       "4      fb160bc5168dd942886289b772987a28ca28ad687e1f92...  \n",
       "...                                                  ...  \n",
       "65692  b0fab595b692dfe7bb2d2df0fe600ad862dc9c3d7c8b9c...  \n",
       "65693  ffe6d70abd5cbb9ace0630da24f6224b4925f3fd6b90b9...  \n",
       "65694  c406e0ff833aaf745bf565970a81d1e779c8fabfdac380...  \n",
       "65695  c406e0ff833aaf745bf565970a81d1e779c8fabfdac380...  \n",
       "65696  e9ad9cb8960378a638ab6924ba52672f361acb27909d0e...  \n",
       "\n",
       "[65697 rows x 6 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:38:10.070949Z",
     "iopub.status.busy": "2022-02-13T07:38:10.070690Z",
     "iopub.status.idle": "2022-02-13T07:38:10.074791Z",
     "shell.execute_reply": "2022-02-13T07:38:10.074121Z",
     "shell.execute_reply.started": "2022-02-13T07:38:10.070915Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_test.groupby('customer_id')['target'].agg(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T13:51:54.137086Z",
     "iopub.status.busy": "2022-02-13T13:51:54.136878Z",
     "iopub.status.idle": "2022-02-13T13:51:59.622090Z",
     "shell.execute_reply": "2022-02-13T13:51:59.621359Z",
     "shell.execute_reply.started": "2022-02-13T13:51:54.137061Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "prod_counts = Counter()\n",
    "post_counts = Counter()\n",
    "\n",
    "for line in open('train_dataset.csv'):\n",
    "    _, post, _, target, d, customer_id = line.strip('\\n').split('\\t')\n",
    "    prod_counts.update(target.split('##'))\n",
    "    post_counts[post] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jade HW Skinny Denim TRS', 12116),\n",
       " ('Luna skinny RW', 10748),\n",
       " ('Timeless Midrise Brief', 9145),\n",
       " ('Tilly (1)', 7715),\n",
       " ('Cat Tee.', 5901),\n",
       " ('Simple as That Triangle Top', 5554),\n",
       " ('Shake it in Balconette', 5393),\n",
       " ('Despacito', 5047),\n",
       " ('Tilda tank', 4949),\n",
       " ('Simple as that Cheeky Tanga', 4903),\n",
       " ('Nora T-shirt', 4760),\n",
       " ('Skinny Ankle R.W Brooklyn', 4723),\n",
       " ('Pluto RW slacks (1)', 4480),\n",
       " ('SUPREME RW tights', 4332),\n",
       " ('Primo slacks', 4283),\n",
       " ('Madison skinny HW (1)', 4121),\n",
       " ('7p Basic Shaftless', 4101),\n",
       " ('Julia RW Skinny Denim TRS', 3914),\n",
       " ('Hazelnut Push Melbourne', 3636),\n",
       " ('Brit Baby Tee', 3563),\n",
       " ('Kanta slacks RW', 3493),\n",
       " ('Therese tee', 3482),\n",
       " ('Melrose', 3325),\n",
       " ('Lazer Razer Brief', 3289),\n",
       " ('Perrie Slim Mom Denim TRS', 3253),\n",
       " ('New Girl Push Top', 3174),\n",
       " ('RICHIE HOOD', 3169),\n",
       " ('SUPREME tights', 3165),\n",
       " ('Becka hoodie', 3126),\n",
       " ('Charlie Top', 3090),\n",
       " ('Mariette Blazer', 3084),\n",
       " ('Shaping Skinny H.W', 2993),\n",
       " ('Moa tank', 2971),\n",
       " ('Lucy blouse', 2912),\n",
       " ('Push Up Jegging L.W', 2853),\n",
       " ('3p Sneaker Socks', 2800),\n",
       " ('PETAR SWEATSHIRT', 2784),\n",
       " ('HAVANA HW tights', 2773),\n",
       " ('Chestnut strap top', 2772),\n",
       " ('Jade Denim TRS', 2772),\n",
       " ('Scallop 5p Socks', 2725),\n",
       " ('Gyda!', 2683),\n",
       " ('Greta Thong Mynta Low 3p', 2671),\n",
       " ('Queen Sweater', 2662),\n",
       " ('Skinny H.W Ankle Queens', 2602),\n",
       " ('Kelso HW fancy', 2571),\n",
       " ('Sirpa Basic TVP', 2504),\n",
       " ('Tess Tee.', 2489),\n",
       " ('Jeggings H.W', 2447),\n",
       " ('Curvy Jeggings HW Ankle', 2441),\n",
       " ('Claudine', 2430),\n",
       " ('Matey', 2379),\n",
       " ('Baraboom (1)', 2368),\n",
       " ('Gyda blouse', 2360),\n",
       " ('Tilly', 2349),\n",
       " ('Milk RW slack', 2323),\n",
       " ('Charlotte Brazilian Aza.Low 2p', 2227),\n",
       " ('Velvet scrunchie', 2225),\n",
       " ('S.Skinny L.W Epic', 2209),\n",
       " ('Timeless Highwaist', 2188),\n",
       " ('Embrace S.Skinny Ankle H.W', 2149),\n",
       " ('Bama', 2144),\n",
       " ('Calista (1)', 2138),\n",
       " ('Ringo hipbelt', 2100),\n",
       " ('RONNY R-NECK', 2077),\n",
       " ('Skinny R.W Chic', 2067),\n",
       " ('Tiblisi paperwaist tapered', 2051),\n",
       " ('CHARLIE SKIRT', 2048),\n",
       " ('Timeless Triangle Top', 2034),\n",
       " ('Ozzy Denim Shorts', 2030),\n",
       " ('Alex Trs (J)', 2012),\n",
       " ('Jade Trash HW Skinny Denim TRS', 1964),\n",
       " ('Pamela Shorts HW', 1955),\n",
       " ('Henry polo (1)', 1951),\n",
       " ('Jennifer tee', 1927),\n",
       " ('Timeless Cheeky Brief', 1896),\n",
       " ('ESSENTIAL TANKTOP LACE TVP', 1881),\n",
       " ('Shaping Skinny R.W', 1848),\n",
       " ('Jen tee', 1827),\n",
       " ('Twenty HW tapered', 1816),\n",
       " ('Panda skate dress j', 1808),\n",
       " ('Jennifer', 1798),\n",
       " ('SIRPA', 1765),\n",
       " ('20 den 2p Tights', 1758),\n",
       " ('PETER POLO', 1750),\n",
       " ('vermont fancy slacks (1)', 1740),\n",
       " ('Glamping', 1712),\n",
       " ('Gyda- (1)', 1712),\n",
       " ('RONNY REG RN T-SHIRT', 1694),\n",
       " ('Gyda-', 1677),\n",
       " ('Tilly.', 1673),\n",
       " ('Shaping Skinny R.W.', 1670),\n",
       " ('Box 4p Tights', 1665),\n",
       " ('Vintage Slim HW ankle consc.', 1665),\n",
       " ('Greta Ch hipster ctn 3p', 1645),\n",
       " ('Simone', 1640),\n",
       " ('Harrison (1)', 1639),\n",
       " ('Bowie', 1638),\n",
       " ('Bird tee', 1624),\n",
       " ('Rebecca or Delphine shirt', 1620),\n",
       " ('Brittany LS', 1616),\n",
       " ('Cornelia Thong LP', 1615),\n",
       " ('Mona', 1604),\n",
       " ('Perrie Trash HW Denim TRS', 1604),\n",
       " ('Flock (1)', 1598),\n",
       " ('Sorrel', 1586),\n",
       " ('Basic sweatpants', 1580),\n",
       " ('Doris L/S', 1572),\n",
       " ('Maja Cardigan TVP', 1553),\n",
       " ('Claudine t-shirt', 1533),\n",
       " ('Sandy', 1531),\n",
       " ('claudine', 1526),\n",
       " ('Bow HW paperwaist', 1520),\n",
       " ('Rachel LS TVP', 1515),\n",
       " ('Peg', 1513),\n",
       " ('Isabella', 1505),\n",
       " ('OP Push Melbourne^', 1504),\n",
       " ('Antonia heavy t-shirt', 1498),\n",
       " ('Milk RW slacks', 1497),\n",
       " ('Mom Fit Ultra HW', 1491),\n",
       " ('Clarence Push Wireless Farg', 1488),\n",
       " ('Agnes LS R-neck', 1480),\n",
       " ('Bradley.', 1472),\n",
       " ('Nirvana', 1450),\n",
       " ('Minja top', 1447),\n",
       " ('Ivy jumpsuit w', 1427),\n",
       " ('Frille', 1426),\n",
       " ('Cinderella fold', 1425),\n",
       " ('Cissi tube top', 1421),\n",
       " ('Calista cardigan.', 1420),\n",
       " ('Vanessa 2-pack', 1420),\n",
       " ('Embrace S.Skinny H.W Trash', 1420),\n",
       " ('Heavy jsy long leg', 1411),\n",
       " ('Skirt Mini', 1410),\n",
       " ('Olga Tank TVP', 1409),\n",
       " ('Jennifer (1)', 1407),\n",
       " ('Hayes slim trouser', 1406),\n",
       " ('Timeless Sports Top', 1398),\n",
       " ('Henry polo. (1)', 1398),\n",
       " ('Eleven top', 1390),\n",
       " ('Lazer Razer Push Up', 1379),\n",
       " ('Charlotte SP Andes', 1373),\n",
       " ('Billie', 1370),\n",
       " ('Timeless Push Triangle(1)', 1366),\n",
       " ('Amalia', 1364),\n",
       " ('Kajsa HW', 1363),\n",
       " ('Strap top', 1347),\n",
       " ('Beverly HW Loose Mom Fit Dnm', 1345),\n",
       " ('Jafar', 1342),\n",
       " ('Leona', 1339),\n",
       " ('Mia', 1339),\n",
       " ('Hazelnut Brazilian Azalea Low', 1330),\n",
       " ('IZZY TEE', 1329),\n",
       " ('FRAME Easy Iron', 1312),\n",
       " ('Tove top.', 1304),\n",
       " ('Olga LL PJ (J)', 1279),\n",
       " ('Lady Di', 1278),\n",
       " ('Lima SS.', 1275),\n",
       " ('Jennifer Top', 1275),\n",
       " ('Highwaist 30 den 1p Tights', 1274),\n",
       " ('Desert Top', 1273),\n",
       " ('Tonia shorts', 1269),\n",
       " ('Richie Regular Hood', 1267),\n",
       " ('SUPREME TIGHTS', 1260),\n",
       " ('ED Pamela (1)', 1257),\n",
       " ('Talia (1)', 1251),\n",
       " ('OP Brazilian 2p Low (Acacia)', 1244),\n",
       " ('Pattern 7p Socks', 1243),\n",
       " ('Tequila shorts denim/fancy', 1238),\n",
       " ('Knot Bitter Top', 1235),\n",
       " ('Tara turtleneck top', 1229),\n",
       " ('Fissa Push Melbourne', 1223),\n",
       " ('Griezman', 1223),\n",
       " ('Hazelnut Brazilian Acacia Low', 1221),\n",
       " ('Sorrel(1)', 1221),\n",
       " ('Glamping.(1)', 1221),\n",
       " ('The Low Line Highwaist', 1218),\n",
       " ('Basic 7p Shaftless', 1214),\n",
       " ('1pk Fun', 1214),\n",
       " ('Son V-neck', 1210),\n",
       " ('Prima', 1203),\n",
       " ('Iris Linen Jogger R.W TVP', 1201),\n",
       " ('KARIN sports bra', 1199),\n",
       " ('Victorville HW Pull-on TRS', 1199),\n",
       " ('Goldie tank top', 1196),\n",
       " ('Super Skinny L.W Epic', 1193),\n",
       " ('Haze LS', 1183),\n",
       " ('Ridge', 1183),\n",
       " ('Hudson shorts', 1182),\n",
       " ('Shenzi LP', 1177),\n",
       " ('Gemma Woven TRS', 1176),\n",
       " ('Epic Padded Swimsuit', 1175),\n",
       " ('Juan', 1166),\n",
       " ('Alex Jogger (J)', 1162),\n",
       " ('Superwoman Superpush', 1160),\n",
       " ('Victoria RW Pull- On TRS', 1153),\n",
       " ('Fiona brazilian (Acacia) 4p', 1153),\n",
       " ('Annette', 1149),\n",
       " ('Orlando C&S Push', 1148),\n",
       " ('Bama(1)', 1147),\n",
       " ('Rose thong 7-pack(1)', 1143),\n",
       " ('Luna skinny 5 pkt', 1141),\n",
       " ('OP T-shirt Milano', 1139),\n",
       " ('Bella l/s', 1134),\n",
       " ('Bob V-neck', 1133),\n",
       " ('Iris Linen Jogger R.W', 1131),\n",
       " ('Brooke Shorts R.W', 1128),\n",
       " ('Lucien', 1121),\n",
       " ('Lazer Razer Adj. push triangle', 1121),\n",
       " ('Timeless Padded Swimsuit', 1116),\n",
       " ('Enter treggings', 1113),\n",
       " ('BOULEVARD TEE TVP', 1101),\n",
       " ('Maja Cardigan', 1098),\n",
       " ('Space 5 pkt tregging', 1097),\n",
       " ('Sweet and Bitter Top', 1092),\n",
       " ('Mel maxi dress  W', 1086),\n",
       " ('Drizzle', 1086),\n",
       " ('Latte slacks (1)', 1085),\n",
       " ('Love Affair Triangle Top', 1082),\n",
       " ('Woody', 1079),\n",
       " ('Sibling HW', 1077),\n",
       " ('Kelso', 1077),\n",
       " ('Jacket Slim', 1076),\n",
       " ('Rihanna', 1067),\n",
       " ('Skinny 5pkt Lowprice', 1067),\n",
       " ('Juanos', 1065),\n",
       " ('Timeless Tie Tanga', 1059),\n",
       " ('V-NECK SS SLIM FIT', 1051),\n",
       " ('Mom HW Ankle Consc', 1051),\n",
       " ('Kanta RW Slacks', 1049),\n",
       " ('Ginger Thong Maple Low 3p', 1048),\n",
       " ('Uno Hood (1)', 1046),\n",
       " ('Thyme top', 1042),\n",
       " ('Tove', 1037),\n",
       " ('Georgina', 1035),\n",
       " ('Sascha pullover hoodie', 1034),\n",
       " ('Basic 7p shaftless pattern', 1033),\n",
       " ('Matey(1)', 1032),\n",
       " ('Jalin linen(1)', 1030),\n",
       " ('Love Affair High Rise Brief', 1030),\n",
       " ('New Girl Wide Side Tanga', 1029),\n",
       " ('Ford', 1028),\n",
       " ('Anita Tank (1)', 1028),\n",
       " ('Cora Dress', 1025),\n",
       " ('Pingu top', 1024),\n",
       " ('Sally Structure TVP', 1017),\n",
       " ('Honey seamless bra', 1016),\n",
       " ('Milk', 1014),\n",
       " ('Lee (1)', 1009),\n",
       " ('Sporty spice top', 1008),\n",
       " ('Sadie Shirt', 1002),\n",
       " ('Apollo seamless HW tights', 1001),\n",
       " ('Nicky long.', 999),\n",
       " ('Ivy shorts', 998),\n",
       " ('Coco', 998),\n",
       " ('Saga body', 997),\n",
       " ('Benny Shorts', 997),\n",
       " ('Zebra sweater TOP PRODUCT', 996),\n",
       " ('Brody', 994),\n",
       " ('Macarena', 994),\n",
       " ('Ellen Thong (Malva) L 3pk', 989),\n",
       " ('Molly dress', 988),\n",
       " ('Emery(1)', 988),\n",
       " ('Tequila shorts (1)', 987),\n",
       " ('Alpha top', 987),\n",
       " ('Skirt Mini Bea', 986),\n",
       " ('Devon basic sweater', 983),\n",
       " ('Flamingo', 982),\n",
       " ('Ginger Ch hipster ctn 3p', 981),\n",
       " ('Madison skinny HW', 979),\n",
       " ('R-NECK SS SLIM FIT', 974),\n",
       " ('Ozzy  HW Denim Shorts', 973),\n",
       " ('KELLY SHIRT', 971),\n",
       " ('Cinderella', 970),\n",
       " ('Fiona Ch Hipster(Poppy)4pk', 967),\n",
       " ('Rose', 966),\n",
       " ('Price tee - TVP- TM', 964),\n",
       " ('CAMILLA OL OFFER', 962),\n",
       " ('GLASSIG ESPADRILLE', 962),\n",
       " ('Support 40 den 1p Tights', 961),\n",
       " ('Khloe RW', 958),\n",
       " ('Shape Up 30 den 1p Tights', 957),\n",
       " ('Trainer 3p sock', 955),\n",
       " ('Spanx alot Swimsuit', 953),\n",
       " ('Noa skinny trouser', 949),\n",
       " ('Maja HW  WovenTRS', 945),\n",
       " ('CERISE top', 944),\n",
       " ('Juan lace strap top', 936),\n",
       " ('Siri Cardigan', 936),\n",
       " ('Skinny H.W Air', 935),\n",
       " ('Bradley trousers', 934),\n",
       " ('Austin basic leather hip belt', 933),\n",
       " ('Serpente HW slim trouser', 931),\n",
       " ('PRICE TEE', 930),\n",
       " ('Petar Sweater', 930),\n",
       " ('Dahlia Push Bralette', 921),\n",
       " ('Charlotte bralette laguna opt2', 919),\n",
       " ('Wowcha Top', 918),\n",
       " ('Femme (1)', 918),\n",
       " ('Daiquiri Pull- On TRS', 916),\n",
       " ('Marina', 916),\n",
       " ('Sky HW jogger', 916),\n",
       " ('Laura short sleeve polo', 915),\n",
       " ('&DENIM Jeggings HW', 914),\n",
       " ('Fissa Thong Maple Low 2p', 914),\n",
       " ('Amanda Tank', 913),\n",
       " ('Miranda', 912),\n",
       " ('Izzy tee', 911),\n",
       " ('7pk basic R sneaker socks', 910),\n",
       " ('Gigi HW', 910),\n",
       " ('Charlotte Push Melbourne', 908),\n",
       " ('Janet', 903),\n",
       " ('Mariette', 896),\n",
       " ('Douglas', 896),\n",
       " ('Alex sweater', 893),\n",
       " ('Jade Denim Petite Trs 1', 893),\n",
       " ('Kendall RW Denim TRS', 892),\n",
       " ('V-neck strap top', 892),\n",
       " ('Rebecca', 887),\n",
       " ('Granny Tie Tanga', 886),\n",
       " ('Dame', 885),\n",
       " ('Lage', 883),\n",
       " ('Timeless Padded Bra', 882),\n",
       " ('Amanda Rib', 879),\n",
       " ('5p Plastic Terry', 871),\n",
       " ('LINNI TEE', 870),\n",
       " ('Timeless High Rise Hipster', 866),\n",
       " ('CHERRY JRSY SKIRT', 862),\n",
       " ('Claudine rib t-shirt', 861),\n",
       " ('Harrison', 858),\n",
       " ('Leonora off-shoulder', 850),\n",
       " ('Long Leggings', 847),\n",
       " ('Trailmix Seamless bralette', 845),\n",
       " ('Strap Top.', 844),\n",
       " ('Push it Push Bra.', 841),\n",
       " ('1pk fun/expressive', 838),\n",
       " ('ESSENTIAL LOVA LINEN', 838),\n",
       " ('V-neck Strap Top.', 835),\n",
       " ('Buckle Up Cheeky Brief', 835),\n",
       " ('Janet sweater', 832),\n",
       " ('Strawberry HW pullon', 830),\n",
       " ('Strap Top 2 pack', 829),\n",
       " ('Frida push up seamless', 829),\n",
       " ('Pomelo', 826),\n",
       " ('Shorts Slim Midas Zip Fly', 825),\n",
       " ('Samantha Push Melbourne', 825),\n",
       " ('SPEEDY CONSCIOUS TEE', 824),\n",
       " ('Harrison short sleeve top CN', 823),\n",
       " ('Desert Sport Top', 822),\n",
       " ('FRAME Easy Care TVP', 820),\n",
       " ('Wow printed tee 6.99', 820),\n",
       " ('Lemon HW', 817),\n",
       " ('Robin blazer', 813),\n",
       " ('Ciara wide cropped HW', 813),\n",
       " ('Rachel', 812),\n",
       " ('Virgo Hip belt', 811),\n",
       " ('40 den 2p Tights', 811),\n",
       " ('ESSENTIAL TANKTOP LACE', 811),\n",
       " ('Midnight', 810),\n",
       " ('DENISE SHIRT S.0', 809),\n",
       " ('TANJA SKIRT', 808),\n",
       " ('Gabbi tank/nina/nelia', 808),\n",
       " ('Cat Tee', 806),\n",
       " ('Bengal Scarf', 806),\n",
       " ('Bounty', 804),\n",
       " ('Knot Bitter Det Brief', 804),\n",
       " ('Estelle strap dress', 803),\n",
       " ('Kelly 2pk Melbourne push ct', 803),\n",
       " ('Pomme tunic', 802),\n",
       " ('Nicole', 801),\n",
       " ('Woody(1)', 801),\n",
       " ('HAVANA tights', 798),\n",
       " ('Pluto slacks RW', 798),\n",
       " ('Melody dress', 797),\n",
       " ('Waleo HW wide full', 797),\n",
       " ('KARIN SPORTS BRA', 797),\n",
       " ('Vivaldi', 797),\n",
       " ('Florida skirt', 796),\n",
       " ('Anders Tie Brief', 795),\n",
       " ('Sweet & Bitter Mid Tie Brief', 793),\n",
       " ('Duo', 793),\n",
       " ('Kelly Push (Melbourne) ctn 2p', 792),\n",
       " ('MINT TANK S.0', 792),\n",
       " ('Maria Shorts.', 790),\n",
       " ('Samantha Strapless Balconette', 787),\n",
       " ('Bianca linen(1)', 783),\n",
       " ('Becky softpant', 779),\n",
       " ('Shorts R.W Kelly Lee', 778),\n",
       " ('Wowcha HR Brief', 776),\n",
       " ('Simba rib', 776),\n",
       " ('Plain Jane Padded Swimsuit', 775),\n",
       " ('Havana dress SPEED', 775),\n",
       " ('Buckle Up Triangle Top', 774),\n",
       " ('Louise LS', 773),\n",
       " ('Bradley', 773),\n",
       " ('OP Strapless^', 771),\n",
       " ('Villi Body', 770),\n",
       " ('DEXTER LOOSE TANK TOP', 770),\n",
       " ('Lola Brazilian (Acacia) 3pk', 769),\n",
       " ('Sebi', 769),\n",
       " ('CSP Grace body', 769),\n",
       " ('Ginger Top', 769),\n",
       " ('Fancy Pants', 765),\n",
       " ('C Lolly Midrise Cheeky Brief', 765),\n",
       " ('Orvar strap top', 762),\n",
       " ('Breadwinner Top', 761),\n",
       " ('Fiona Bikini (Clover) 4pk', 761),\n",
       " ('C Antibes Tie Tanga', 761),\n",
       " ('DEXTER TANK', 760),\n",
       " ('OP Cheeky hipster 2p', 760),\n",
       " ('C Antibes Triangle', 759),\n",
       " ('Mini Flare R.W Utility', 753),\n",
       " ('Long leggings update', 753),\n",
       " ('Mike tee', 752),\n",
       " ('C Montauk Highwaist Brazilian', 751),\n",
       " ('Heavy plain 2 p tights', 750),\n",
       " ('Flock', 749),\n",
       " ('Khloe SP Seamless Andes', 747),\n",
       " ('Lauren', 745),\n",
       " ('Lazer Razer Padded Wire', 745),\n",
       " ('C Jackpot Swimsuit', 745),\n",
       " ('Tory price tee', 743),\n",
       " ('Sigge Shorts', 742),\n",
       " ('Mac', 741),\n",
       " ('Control Top 30 den 1p Tights', 741),\n",
       " ('Emily', 740),\n",
       " ('Slim 5pkt Midprice', 740),\n",
       " ('Zebra- TVP- TM', 739),\n",
       " ('Dolly dress', 739),\n",
       " ('James Biker', 738),\n",
       " ('Latte RW slacks', 738),\n",
       " ('Luisa tee', 737),\n",
       " ('BOUNTY', 734),\n",
       " ('All That Jazz Push Up Bra', 734),\n",
       " ('Kelly Lace Padded Idro 2p', 733),\n",
       " ('Freedom', 732),\n",
       " ('Ossian', 729),\n",
       " ('Johnny', 728),\n",
       " ('Claudine rib', 728),\n",
       " ('Lilly Tank (1)', 728),\n",
       " ('Vivi boatneck', 726),\n",
       " ('Grace', 726),\n",
       " ('Pamela', 725),\n",
       " ('DINGO TEE', 723),\n",
       " ('Dakar HW tapered', 723),\n",
       " ('Surfs Up Push Triangle', 722),\n",
       " ('Verina', 718),\n",
       " ('Kendrick Brazilian Anemon', 718),\n",
       " ('Raven', 718),\n",
       " ('BROADWAY SHIRT S.1', 717),\n",
       " ('Starlight', 716),\n",
       " ('Orlando Mynta Thong', 715),\n",
       " ('Alcazar strap dress', 715),\n",
       " ('Solange Skinny R.W', 715),\n",
       " ('Timeless Rem Pads Swimsuit', 712),\n",
       " ('Angela hipster', 712),\n",
       " ('Pretty Please Triangle Top', 708),\n",
       " ('Svea Cropped Tank', 708),\n",
       " ('Blueberry', 707),\n",
       " ('Kirsten', 707),\n",
       " ('Ruby', 706),\n",
       " ('Danja Sweater', 706),\n",
       " ('Sun', 706),\n",
       " ('Minami', 704),\n",
       " ('SARGASSO HW ankle tights', 701),\n",
       " ('Mona polo', 696),\n",
       " ('Super Skinny HW ankle Star', 695),\n",
       " ('KELLY SHIRT S9', 694),\n",
       " ('Marianne', 694),\n",
       " ('Nikki Blazer', 694),\n",
       " ('Palermo', 690),\n",
       " ('Daisy', 686),\n",
       " ('Robin 3pk Fancy', 686),\n",
       " ('Perrie Slim HW Denim Shorts', 685),\n",
       " ('Ivory ch brazilian 5pk', 684),\n",
       " ('Moa 2 pack tank', 682),\n",
       " ('Gavino', 682),\n",
       " ('Amelie', 682),\n",
       " ('Nicole Top', 682),\n",
       " ('Nicky Long', 681),\n",
       " ('TAZ LONG RN T-SHIRT', 681),\n",
       " ('Marcie(1)', 680),\n",
       " ('Victoria Pull- On TRS', 680),\n",
       " ('Scarf Scrunchie', 680),\n",
       " ('Peggy Trouser', 679),\n",
       " ('Desert Highline Braz. Cheeky', 677),\n",
       " ('Enter(1)', 677),\n",
       " ('Thomas PREMIUM', 676),\n",
       " ('Salvador dress', 676),\n",
       " ('Skinny denim (1)', 676),\n",
       " ('Wannabe Highwaist', 676),\n",
       " ('HM+ Cora tee', 676),\n",
       " ('Evelyn midi dress', 673),\n",
       " ('Surfs Up Tanga', 672),\n",
       " ('Ivory Ch. braz. Low Acacia 3pk', 670),\n",
       " ('Pearl Jam', 670),\n",
       " ('SPEEDY TEE', 669),\n",
       " ('JUST PINK DRESS(1)', 668),\n",
       " ('Cartier (1)', 668),\n",
       " ('Julia Denim Petite Trs 1', 668),\n",
       " ('Mandy', 668),\n",
       " ('Skinny L.W Elite', 667),\n",
       " ('Iris Linen Pull on', 666),\n",
       " ('KELLY SHIRT S.1', 666),\n",
       " ('Maud Blanket', 666),\n",
       " ('Taya Hood', 666),\n",
       " ('Avignon', 666),\n",
       " ('MAYA SKIRT S.0', 665),\n",
       " ('Bloom', 665),\n",
       " ('Amalia dress', 661),\n",
       " ('FORTUNA TEE', 661),\n",
       " ('CROW RIB STRAP TOP', 661),\n",
       " ('Osman', 660),\n",
       " ('ANNA SLUB', 660),\n",
       " ('East HW tapered', 659),\n",
       " ('Rae Push (Melbourne) 2p', 658),\n",
       " ('Anita Tank', 658),\n",
       " ('Zitta Scarf', 656),\n",
       " ('Chaka linnen', 656),\n",
       " ('AUDREY tanktop knot detail', 655),\n",
       " ('Macy', 654),\n",
       " ('DENISE SHIRT S.9', 654),\n",
       " ('Teddy jogger.', 653),\n",
       " ('Enter HW leggings', 653),\n",
       " ('Meet the Parents dress', 653),\n",
       " ('Julie (1)', 652),\n",
       " ('ZEBRA CF TVP', 652),\n",
       " ('Ashley Denim TRS', 651),\n",
       " ('Tropicana Top', 651),\n",
       " ('Sonja sweater dress', 650),\n",
       " ('Kanta slacks', 650),\n",
       " ('Flirty Linnea necklace', 649),\n",
       " ('TILDA HIP BELT', 649),\n",
       " ('Liza Push Melbourne 2pk', 649),\n",
       " ('Liza Thong Low (Malva) 3pk', 648),\n",
       " ('Boyfriend L.W', 648),\n",
       " ('Cora', 647),\n",
       " ('Hercules shirt', 644),\n",
       " ('Dottie', 643),\n",
       " ('Hedda HW leggings', 643),\n",
       " ('Prima(1)', 642),\n",
       " ('VICTOR SLIM VN T-SHIRT', 642),\n",
       " ('SPEARMINT', 641),\n",
       " ('Asta (1)', 641),\n",
       " ('Greta', 639),\n",
       " ('Roy Shorts', 639),\n",
       " ('This is Sally Push Up Bra', 638),\n",
       " ('Vermont essential slacks', 638),\n",
       " ('Tuck cropped sweater', 638),\n",
       " ('Mini Flare HW Bronx', 638),\n",
       " ('Notting Hill', 637),\n",
       " ('Jade Denim HW trs', 637),\n",
       " ('Fred shorties 5-p', 636),\n",
       " ('Wake rib polo', 636),\n",
       " ('Tina Blouse', 635),\n",
       " ('J Tzatziki', 634),\n",
       " ('Nouvelle 1p Stay Up', 634),\n",
       " ('Charlotte Body Push Melbourne', 633),\n",
       " ('COLETTE push up sport bra', 632),\n",
       " ('Ivanovo', 629),\n",
       " ('Walkover Unpadded Swimsuit', 629),\n",
       " ('Boujis strap', 629),\n",
       " ('Herbal hood TOP PRODUCT', 629),\n",
       " ('Speedy Tee', 628),\n",
       " ('Samantha', 628),\n",
       " ('Vanessa rib', 627),\n",
       " ('Olga off shoulder', 627),\n",
       " ('Lazer Razer High Rise Hipster', 626),\n",
       " ('MACARON OL OFFER', 626),\n",
       " ('Fiona', 626),\n",
       " ('Charlotte Bikini Lotus Low', 626),\n",
       " ('Pantha PU leggings', 626),\n",
       " ('Luna destroy (1)', 625),\n",
       " ('Magnolia', 624),\n",
       " ('Anders Super Push Bra', 624),\n",
       " ('Straight Edge 5p Socks', 624),\n",
       " ('Trinny', 623),\n",
       " ('Stardust', 620),\n",
       " ('Despacito 1', 619),\n",
       " ('Topi bodycon dress j', 617),\n",
       " ('HEAVEN shaping HW tight', 616),\n",
       " ('B Leila Sarong', 615),\n",
       " ('1pk XMAS', 614),\n",
       " ('1p Short Socks', 614),\n",
       " ('PLOPP tights', 614),\n",
       " ('Rose thong', 611),\n",
       " ('Bristol jersey blz', 611),\n",
       " ('Kia Paperbag (1)', 611),\n",
       " ('Summer pants (Saigon)', 611),\n",
       " ('Desert Highwaist Cheeky Brazil', 611),\n",
       " ('Baby Lock Me Up Tie Tanga', 610),\n",
       " ('Claudine (1)', 610),\n",
       " ('Buckle Roo Cheeky V-Brief', 608),\n",
       " ('Papi Chulo Top', 606),\n",
       " ('Girlfriend R.W.', 606),\n",
       " ('Chubba Chubb Highwaist brazili', 605),\n",
       " ('This Is Sally Tie Tanga', 605),\n",
       " ('Bahama dress', 605),\n",
       " ('Mimosa padded softbra P2', 604),\n",
       " ('Straight HW ankle Femme', 604),\n",
       " ('Timeless Cheeky V- Brief', 603),\n",
       " ('DIV Tess tee', 601),\n",
       " ('Yen', 600),\n",
       " ('Lazer Razer Roundneck swimsuit', 600),\n",
       " ('Simpson', 600),\n",
       " ('Chip', 599),\n",
       " ('Pingu spring', 599),\n",
       " ('TOM FANCY', 599),\n",
       " ('Samantha 2p Brazilian (Acacia)', 599),\n",
       " ('Karin padded sport bra', 599),\n",
       " ('HERBAL HOOD TVP', 598),\n",
       " ('Slim 5pkt Lowprice', 597),\n",
       " ('Lindsay Sl-set (W)', 596),\n",
       " ('SKINNY BASIC 89', 595),\n",
       " ('Summer strap dress', 595),\n",
       " ('Sportsneaker 3p socks', 595),\n",
       " ('Kaj tapered', 594),\n",
       " ('Lauper Long Sweater', 593),\n",
       " ('Lindsay Kimono (W)', 593),\n",
       " ('Greece Shape Swimsuit', 593),\n",
       " ('Freja tank top', 592),\n",
       " ('KARIN MID SUPPORT BRA', 591),\n",
       " ('Tiger Cheeky Brief', 591),\n",
       " ('Walk Away Highwaist Brief', 591),\n",
       " ('Hood W Zip', 590),\n",
       " ('Lazer Razer Triangle Top', 590),\n",
       " ('CS Paula dress', 590),\n",
       " ('Skirt Mini Stretch Edie', 589),\n",
       " ('Rae Lace Thong (Magnolia 3p', 588),\n",
       " ('Bow paperwaist', 588),\n",
       " ('ROY SLIM RN T-SHIRT', 588),\n",
       " ('Alpha essential top', 587),\n",
       " ('Lindsay N-slip (W)', 586),\n",
       " ('Ida Panel Jogger', 585),\n",
       " ('Baby Love Cheeky Brief', 585),\n",
       " ('Timeles Cheeky Brief', 585),\n",
       " ('Taz Tee', 584),\n",
       " ('Lilly tank', 583),\n",
       " ('Stella RW skinny cropped CN', 582),\n",
       " ('Lily blouse', 582),\n",
       " ('Flora(1)', 582),\n",
       " ('DeLuca pull on TVP RW', 582),\n",
       " ('Bling bling', 579),\n",
       " ('Wannabe Superpush', 579),\n",
       " ('Ophelia Push Melbourne Cradle', 578),\n",
       " ('CASSIM ROLLNECK', 578),\n",
       " ('Barton midi skirt', 578),\n",
       " ('Skinny L.W Grand', 576),\n",
       " ('James basic hip belt', 576),\n",
       " ('Fancy Pants (1)', 575),\n",
       " ('Vickan dress w', 575),\n",
       " ('Hope', 575),\n",
       " ('Superskinny', 574),\n",
       " ('Chicago dress', 574),\n",
       " ('Shorts HW Pixie', 574),\n",
       " ('Ruccola', 574),\n",
       " ('Dalila sweater', 574),\n",
       " ('Kalas puffer', 573),\n",
       " ('CINDY tights conscious', 573),\n",
       " ('Alm Trench', 572),\n",
       " ('Swish HR wide side Brief', 571),\n",
       " ('Aubergine', 571),\n",
       " ('C Montauk Bandeau', 569),\n",
       " ('Spice it Up Skimpy Tanga', 569),\n",
       " ('Skinny L.W Bargain (1)', 568),\n",
       " ('New Girl Cheeky Tanga', 568),\n",
       " ('Karin headband', 568),\n",
       " ('Kim pinafore dress', 567),\n",
       " ('Tulip', 567),\n",
       " ('30p pins', 566),\n",
       " ('Vovve shorts', 565),\n",
       " ('Dixie tee 9.99', 564),\n",
       " ('Portobello', 564),\n",
       " ('10p Jersey Terry', 563),\n",
       " ('Moscow', 563),\n",
       " ('Lennox', 563),\n",
       " ('Pluto OTS', 562),\n",
       " ('JESSY JERSEY SKIRT', 561),\n",
       " ('Malin Leggings', 560),\n",
       " ('Ronny R-Neck', 560),\n",
       " ('Zidane jumpsuit', 560),\n",
       " ('Vichy 5pkt slim trouser', 558),\n",
       " ('Simba', 558),\n",
       " ('C Lolly Top', 557),\n",
       " ('Isabella shirt', 556),\n",
       " ('Pretty Please Cheeky Tanga', 556),\n",
       " ('Mom Fit Trash', 556),\n",
       " ('Spring', 555),\n",
       " ('Calvin Clean wire bra', 553),\n",
       " ('Enter', 553),\n",
       " ('Mercery', 552),\n",
       " ('Skinny 5pkt Midprice', 552),\n",
       " ('Baraboom', 552),\n",
       " ('Diana jumpsuit', 552),\n",
       " ('Tulum Triangle Top', 552),\n",
       " ('Jade HW denim trs', 552),\n",
       " ('Techno', 551),\n",
       " ('Timeless Regular V Brief Price', 551),\n",
       " ('Everlacing Love Highwaist', 550),\n",
       " ('Bob v-neck 2-pack', 549),\n",
       " ('Florida', 549),\n",
       " ('Control Lt 40 den 2p Tights', 549),\n",
       " ('Buckle Roo Triangle Top', 548),\n",
       " ('Hilly Biker 2pk HW LS', 548),\n",
       " ('Asa smock top', 546),\n",
       " ('ED Nora tee', 546),\n",
       " ('Billie.', 545),\n",
       " ('APOLLO HW seamless tights', 545),\n",
       " ('Bondi Babe Price Swimsuit', 544),\n",
       " ('Bernie', 544),\n",
       " ('Small dot 1p Tights', 544),\n",
       " ('Lova Linen v neck', 544),\n",
       " ('Holly Push Melbourne', 544),\n",
       " ('Miranda(1)', 543),\n",
       " ('DENISE S.8', 543),\n",
       " ('Elsa', 542),\n",
       " ('Beverly Hills Wire Bra', 542),\n",
       " ('Peg fineknit', 541),\n",
       " ('Lee rib', 541),\n",
       " ('FIG STRAP S.0', 540),\n",
       " ('Chiara body', 540),\n",
       " ('PAUL  R-NECK', 540),\n",
       " ('Hayes', 539),\n",
       " ('Osman (1)', 539),\n",
       " ('Timeless Low V Shape Brief', 539),\n",
       " ('Ursula Top', 539),\n",
       " ('Emerald (1)', 539),\n",
       " ('Raymond fleece', 538),\n",
       " ('Carola sweater', 538),\n",
       " ('Papi Chulo Tie Tanga', 538),\n",
       " ('Bambi', 538),\n",
       " ('James basic hip belt (1)', 537),\n",
       " ('Monet RW wide full', 537),\n",
       " ('Baby Lock Me Up Push Triangle', 535),\n",
       " ('Nicole Highwaist', 534),\n",
       " ('Luna (1)', 534),\n",
       " ('5pk regular fancy', 533),\n",
       " ('Mimosa Push Melbourne Opt.2', 532),\n",
       " ('Monica', 532),\n",
       " ('Django', 531),\n",
       " ('COLETTE PUSH UP BRA', 530),\n",
       " ('Dalston blazer', 529),\n",
       " ('Love Shack Cheeky Brief', 528),\n",
       " ('Chaka linen', 527),\n",
       " ('COZY DORRI TOP', 527),\n",
       " ('Thelma tie top', 527),\n",
       " ('Carla culotte', 526),\n",
       " ('Marais', 525),\n",
       " ('Lumiere Brazilian.', 524),\n",
       " ('SORRENTO RW trs', 524),\n",
       " ('Perrie Denim Shorts', 524),\n",
       " ('ROBIN HOOD', 524),\n",
       " ('Samantha Thong Mynta Low', 524),\n",
       " ('Samantha Hipster Ch. Poppy Low', 524),\n",
       " ('Eleonor button dress', 523),\n",
       " ('Tulip jumper', 521),\n",
       " ('Fake 1p Leggings', 520),\n",
       " ('Lazer Razer Sport Top', 518),\n",
       " ('IZZY loose tee (1)', 518),\n",
       " ('Greta ctn brazilian 3p', 517),\n",
       " ('Mom HW Shorts', 517),\n",
       " ('Santiago', 516),\n",
       " ('Mooncake', 516),\n",
       " ('Theron', 515),\n",
       " ('Pheobe dress', 515),\n",
       " ('Aguilera maxidress', 515),\n",
       " ('Dallas', 515),\n",
       " ('Small basic scrunchie', 514),\n",
       " ('Rocky!', 513),\n",
       " ('Skinny H.W Ankle', 513),\n",
       " ('Rosemary', 512),\n",
       " ('Milkshake Balconette', 512),\n",
       " ('Ursula Cheeky V Brief', 512),\n",
       " ('Bella waistbelt', 511),\n",
       " ('NORWAY TECH FLEECE', 511),\n",
       " ('Timeless Top', 511),\n",
       " ('Taylor blouse', 510),\n",
       " ('Babylock Me Up Tie Tanga', 510),\n",
       " ('BROADWAY S.0', 509),\n",
       " ('Basic sweatpants 1', 509),\n",
       " ('Tess Tee', 509),\n",
       " ('Yasmine LS', 508),\n",
       " ('Matcha', 508),\n",
       " ('Goji dress w', 508),\n",
       " ('Shirtdress Lou', 508),\n",
       " ('Frankie RW pull on', 508),\n",
       " ('Linni Tee', 506),\n",
       " ('Mary Scarf', 506),\n",
       " ('Drake', 505),\n",
       " ('Evie thong 3p', 504),\n",
       " ('Sporty Spice Highwaist Brazil', 504),\n",
       " ('SKINNY SS 89', 504),\n",
       " ('C Lolly Bandeau', 504),\n",
       " ('1p Fun Socks', 503),\n",
       " ('Frugan.', 503),\n",
       " ('Swish Super Push', 503),\n",
       " ('L Lilo Pile Coat', 503),\n",
       " ('HONEY seamless bra (1)', 502),\n",
       " ('Venice wireless fargo', 502),\n",
       " ('LS Reggipetto Triangle Top', 502),\n",
       " ('1pk Fun 1', 502),\n",
       " ('ESSENTIAL AGNES', 502),\n",
       " ('Karlshamn strap top', 502),\n",
       " ('Solange 5pkt TVP RW', 502),\n",
       " ('Karin mid support bra', 501),\n",
       " ('Paco Hairy Sweater', 501),\n",
       " ('Winnie top', 501),\n",
       " ('Dina body', 501),\n",
       " ('JESSY SKIRT', 500),\n",
       " ('SIGNE BOAT NECK', 499),\n",
       " ('Spice it Up Triangle', 498),\n",
       " ('Lia Slacks tie belt', 498),\n",
       " ('Lily dress', 497),\n",
       " ('Racing shorts', 497),\n",
       " ('Marc dress', 497),\n",
       " ('Babette long', 496),\n",
       " ('Ginger Highwaist', 496),\n",
       " ('VALENTINE LONGSLEEVE', 495),\n",
       " ('B David Kaftan', 495),\n",
       " ('Control Top 50 den 1p Tights', 495),\n",
       " ('Ophelia Padded Soft Bra', 495),\n",
       " ('Ellen linen', 494),\n",
       " ('Paulina blouse', 494),\n",
       " ('Tequila denim/fancy shorts', 494),\n",
       " ('Bebe Sl-set (J)', 493),\n",
       " ('Tiger Bandeau', 493),\n",
       " ('Margarita Push Melbourne', 493),\n",
       " ('Bengal', 493),\n",
       " ('Holly Thong Mynta 2p', 493),\n",
       " ('Charlotte Pull On Soft Bra', 491),\n",
       " ('Florentina', 490),\n",
       " ('Wrappy Dress', 489),\n",
       " ('Vermont Summer Slacks', 489),\n",
       " ('Burmilla (1)', 489),\n",
       " ('Capri blazer', 489),\n",
       " ('Gainsbourgh', 488),\n",
       " ('Skirt Shine', 488),\n",
       " ('Oregano dress', 488),\n",
       " ('LOLA SANDAL', 487),\n",
       " ('Dahlia Brazilian Azalea Low', 487),\n",
       " ('Tanya mockneck LS', 487),\n",
       " ('Jacket Oversize', 487),\n",
       " ('Martini', 486),\n",
       " ('Bruce Skinny Denim Trs', 486),\n",
       " ('Timeless High Apex Tri Top', 485),\n",
       " ('Kelly jumpsuit', 485),\n",
       " ('Charlie A-line', 484),\n",
       " ('Fidde tee(1)', 484),\n",
       " ('Simpson(1)', 483),\n",
       " ('Pitcher RW', 483),\n",
       " ('Kendall bikerpant', 483),\n",
       " ('PANORAMA sports bra', 482),\n",
       " ('Mira body', 482),\n",
       " ('Roll Up Tee', 482),\n",
       " ('Elie', 482),\n",
       " ('Boulevard- TVP- TM', 482),\n",
       " ('Paulina top', 482),\n",
       " ('Firepower seamless bralette', 481),\n",
       " ('Walk Away Top', 481),\n",
       " ('Bagira Thong Mynta 2p', 481),\n",
       " ('Sorreli', 481),\n",
       " ('J Persilja', 481),\n",
       " ('Polka jsy blazer', 481),\n",
       " ('Katsu', 481),\n",
       " ('Kendrick Padded Soft Bra', 481),\n",
       " ('Karma dress', 480),\n",
       " ('Super Skinny HW Ankle Vanessa', 480),\n",
       " ('Control Top 100 den 1p Tights', 479),\n",
       " ('Noah cowl neck dress', 478),\n",
       " ('Teddy turtleneck', 478),\n",
       " ('Jacket Core', 477),\n",
       " ('Zoe L/S', 477),\n",
       " ('Lucky jumpsuit', 476),\n",
       " ('janita', 476),\n",
       " ('Felix HW', 476),\n",
       " ('Sunny', 476),\n",
       " ('Alba Push-Up Biker HW FS', 476),\n",
       " ('TOM SOLID', 476),\n",
       " ('Speedy tee (C)', 475),\n",
       " ('NORA RW shorts innerbriefs', 475),\n",
       " ('Katie Skirt', 475),\n",
       " ('Tuna', 475),\n",
       " ('Tequila denim', 475),\n",
       " ('Venice wide side thong', 474),\n",
       " ('Granny Push Up Bra', 474),\n",
       " ('Charlotte Padded Soft Bra H&E', 474),\n",
       " ('Toulon jumper', 474),\n",
       " ('J Persilja(1)', 473),\n",
       " ('Support 20 den 1p tights', 473),\n",
       " ('Adore strapless push', 472),\n",
       " ('Ludwig', 472),\n",
       " ('Riviera S/S', 472),\n",
       " ('Dingo tee TVP', 471),\n",
       " ('Bailey', 471),\n",
       " ('Lee Parka', 471),\n",
       " ('ORBIT HW hotpants', 470),\n",
       " ('Apple', 470),\n",
       " ('Lindy linen shirt', 470),\n",
       " ('W YODA KNIT OL OFFER', 470),\n",
       " ('Skinny H.W', 469),\n",
       " ('Ring Ring Triangle Top', 468),\n",
       " ('S Timeless High Wide Side Brie', 468),\n",
       " ('Snow chino TVP RW', 467),\n",
       " ('Bellini price CF', 467),\n",
       " ('Tigra knitted headband', 467),\n",
       " ('Shaun', 466),\n",
       " ('2p Samantha Brazilian (Acacia)', 466),\n",
       " ('Zenit highlift sneaker', 466),\n",
       " ('Manchester dress', 466),\n",
       " ('Liza 2p padded wireless rio mc', 466),\n",
       " ('Darby blouse', 466),\n",
       " ('Coral jumpsuit', 465),\n",
       " ('Wrap Queen Top', 465),\n",
       " ('Dusk Padded T-shirt', 464),\n",
       " ('Fletcher', 464),\n",
       " ('Gwen Jersey Top', 464),\n",
       " ('Gisela', 464),\n",
       " ('Rio', 464),\n",
       " ('Samantha Padded T-shirt Milano', 464),\n",
       " ('SPEED Apple', 464),\n",
       " ('Straight R.W', 464),\n",
       " ('Esther', 463),\n",
       " ('Hazel', 463),\n",
       " ('Glow Triangle Top', 462),\n",
       " ('Pia Party', 462),\n",
       " ('Ivy playsuit w', 461),\n",
       " ('Milka', 460),\n",
       " ('ED Madison Skinny HW', 460),\n",
       " ('Vovve shorts.', 460),\n",
       " ('Neve Off Shoulder', 459),\n",
       " ('Scary Spice Top', 459),\n",
       " ('Flora hip belt (1)', 459),\n",
       " ('Lasse Fluff', 459),\n",
       " ('PRINCE ERIC BASIC TEE', 458),\n",
       " ('DENISE SHIRT S.1', 458),\n",
       " ('MARY LS', 458),\n",
       " ('X-tina Brazilian', 458),\n",
       " ('RA RW shorts conscious(1)', 457),\n",
       " ('R-NECK BASIC FIT FANCY', 456),\n",
       " ('AGNES isw 45', 456),\n",
       " ('STRONG HW seamless tights', 455),\n",
       " ('Selena shopper (1)', 455),\n",
       " ('Riviera L/S', 455),\n",
       " ('Molly Twill TRS', 454),\n",
       " ('Swift Dress(1)', 453),\n",
       " ('4p Claw', 453),\n",
       " ('BROADWAY S.9', 452),\n",
       " ('Breadwinner Cheeky Brief', 451),\n",
       " ('Toulouse', 451),\n",
       " ('Tulum Tie Brief', 451),\n",
       " ('Jenny Sock 5-pack', 450),\n",
       " ('Mimosa 2p Thong Mynta', 450),\n",
       " ('Mist Conscious Rib Tank', 450),\n",
       " ('Bono NW slim denim', 450),\n",
       " ('Amber', 449),\n",
       " ('Burmilla blazer', 448),\n",
       " ('ARTICHOKE SLIM FIT POLO', 447),\n",
       " ('Nala polo', 447),\n",
       " ('Molly HW Ankle TRS', 447),\n",
       " ('Boyfriend Shorts', 446),\n",
       " ('Shake', 446),\n",
       " ('Miso', 446),\n",
       " ('Reggie (1)', 446),\n",
       " ('Glow Cheeky Tanga', 445),\n",
       " ('Alison', 445),\n",
       " ('Danny Tie Brief', 445),\n",
       " ('Ellen Shortie Daisy Low 3p', 444),\n",
       " ('Asher', 444),\n",
       " ('Vickan baby tee', 443),\n",
       " ('Pep leggings', 443),\n",
       " ('Make Over Brief', 442),\n",
       " ('Stardust linen', 442),\n",
       " ('Bridget Sweater TVP', 441),\n",
       " ('Norway hood jacket', 440),\n",
       " ('Solange 5 pkt', 440),\n",
       " ('Cornelia Push Melbourne LP', 439),\n",
       " ('Seahorse', 439),\n",
       " ('Dragonfly dress', 439),\n",
       " ('CSP Eva', 439),\n",
       " ('Luve Jumper', 439),\n",
       " ('San fran HW', 439),\n",
       " ('Hamilton Swimsuit', 439),\n",
       " ('Palace strap dress', 439),\n",
       " ('Boy Denim Shorts', 439),\n",
       " ('Birdy HW', 438),\n",
       " ('Timeless Tanga', 438),\n",
       " ('Jonas Slim 5-pkt Trs', 438),\n",
       " ('Fusili', 437),\n",
       " ('Band leggings', 437),\n",
       " ('Lilja top', 437),\n",
       " ('GILDA LEGGINGS', 437),\n",
       " ('Vincent', 437),\n",
       " ('Cindererlla', 437),\n",
       " ('New Vega sneaker', 436),\n",
       " ('Baby Lock Me Up SP', 436),\n",
       " ('Carolina ankle', 436),\n",
       " ('HM+ Track dress', 435),\n",
       " ('Classic Pilot sunglasses', 435),\n",
       " ('Peacock', 435),\n",
       " ('Support 70 den 1p Tights', 435),\n",
       " ...]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T13:51:59.623594Z",
     "iopub.status.busy": "2022-02-13T13:51:59.623336Z",
     "iopub.status.idle": "2022-02-13T13:51:59.702046Z",
     "shell.execute_reply": "2022-02-13T13:51:59.701331Z",
     "shell.execute_reply.started": "2022-02-13T13:51:59.623550Z"
    }
   },
   "outputs": [],
   "source": [
    "prod2id = {'PAD':0, 'UNK':1}\n",
    "for k in prod_counts:\n",
    "    if prod_counts[k] > 10:\n",
    "        prod2id[k] = len(prod2id)\n",
    "id2prod = {i:k for k, i in prod2id.items()}\n",
    "\n",
    "post2id = {'UNK':0}\n",
    "for k in post_counts:\n",
    "    if post_counts[k] > 10:\n",
    "        post2id[k] = len(post2id)\n",
    "id2post = {i:k for k, i in post2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:51:41.269526Z",
     "iopub.status.busy": "2022-02-13T09:51:41.269267Z",
     "iopub.status.idle": "2022-02-13T09:51:41.273392Z",
     "shell.execute_reply": "2022-02-13T09:51:41.272468Z",
     "shell.execute_reply.started": "2022-02-13T09:51:41.269498Z"
    }
   },
   "outputs": [],
   "source": [
    "# articles.loc[100:120, ['prod_name', 'detail_desc', 'article_id']].compute().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T13:52:34.116461Z",
     "iopub.status.busy": "2022-02-13T13:52:34.116214Z",
     "iopub.status.idle": "2022-02-13T13:52:34.120480Z",
     "shell.execute_reply": "2022-02-13T13:52:34.119794Z",
     "shell.execute_reply.started": "2022-02-13T13:52:34.116434Z"
    }
   },
   "outputs": [],
   "source": [
    "target_size = len(id2prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T13:52:34.325268Z",
     "iopub.status.busy": "2022-02-13T13:52:34.324720Z",
     "iopub.status.idle": "2022-02-13T13:52:34.331485Z",
     "shell.execute_reply": "2022-02-13T13:52:34.330658Z",
     "shell.execute_reply.started": "2022-02-13T13:52:34.325232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19923"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T13:53:03.276424Z",
     "iopub.status.busy": "2022-02-13T13:53:03.276113Z",
     "iopub.status.idle": "2022-02-13T13:53:03.284826Z",
     "shell.execute_reply": "2022-02-13T13:53:03.284142Z",
     "shell.execute_reply.started": "2022-02-13T13:53:03.276382Z"
    }
   },
   "outputs": [],
   "source": [
    "# def generate(filename, infer=False):\n",
    "#     for line in open(filename):\n",
    "#         age, post, history, target, _ = line.strip('\\n').split('\\t') \n",
    "#         target = Counter([prod2id.get(p, 0) for p in target.split('##') if p in prod2id])\n",
    "#         s = sum(target.values())\n",
    "# #         target = list(set([prod2id.get(p, 0) for p in target.split('##') if p in prod2id]))\n",
    "# #         if skip_empty and not target:\n",
    "# #             continue\n",
    "#         post = post2id.get(post, 0)\n",
    "        \n",
    "        \n",
    "#         if not infer:\n",
    "#             target_tensor = np.zeros((target_size))\n",
    "#             for t in target:\n",
    "#                 target_tensor[t] = t#/s\n",
    "#             yield ((tf.constant([float(age)], dtype=tf.float64), tf.constant([post], dtype=tf.int32), tf.constant([history])), tf.constant(target_tensor, dtype=tf.float64))\n",
    "#         else:\n",
    "#             yield (tf.constant([float(age)], dtype=tf.float64), tf.constant([post], dtype=tf.int32), tf.constant([history]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T15:03:52.562852Z",
     "iopub.status.busy": "2022-02-13T15:03:52.562528Z",
     "iopub.status.idle": "2022-02-13T15:03:52.576139Z",
     "shell.execute_reply": "2022-02-13T15:03:52.575277Z",
     "shell.execute_reply.started": "2022-02-13T15:03:52.562818Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(filename, infer=False):\n",
    "    for line in open(filename):\n",
    "        age, post, history, target, dat, _ = line.strip('\\n').split('\\t') \n",
    "        target = Counter([prod2id.get(p, 1) for p in target.split('##') if p in prod2id])\n",
    "        history = [prod2id.get(p, 1) for p in history.split('##') if p in prod2id]\n",
    "        h_array = np.zeros(50)\n",
    "        if history:\n",
    "            h_array[-min(50, len(history)):] = history[:50]\n",
    "#         s = sum(target.values())\n",
    "#         target = list(set([prod2id.get(p, 0) for p in target.split('##') if p in prod2id]))\n",
    "#         if skip_empty and not target:\n",
    "#             continue\n",
    "        post = post2id.get(post, 0)\n",
    "        \n",
    "        \n",
    "        if not infer:\n",
    "            target_tensor = np.zeros((target_size))\n",
    "            for t in target:\n",
    "                target_tensor[t] = t#/s\n",
    "            yield ((tf.constant([float(age)], dtype=tf.float64), \n",
    "                    tf.constant([post], dtype=tf.int32), \n",
    "                    tf.constant(h_array, dtype=tf.int32),\n",
    "                    tf.constant([int(dat)-1], dtype=tf.int32)), \n",
    "                   \n",
    "                   tf.constant(target_tensor, dtype=tf.float64))\n",
    "        else:\n",
    "            yield (tf.constant([float(age)], dtype=tf.float64),\n",
    "                   tf.constant([post], dtype=tf.int32), \n",
    "                   tf.constant(h_array, dtype=tf.int32),\n",
    "                   tf.constant([int(dat)-1], dtype=tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:38:11.181918Z",
     "iopub.status.busy": "2022-02-13T07:38:11.181390Z",
     "iopub.status.idle": "2022-02-13T07:38:11.191434Z",
     "shell.execute_reply": "2022-02-13T07:38:11.190579Z",
     "shell.execute_reply.started": "2022-02-13T07:38:11.181875Z"
    }
   },
   "outputs": [],
   "source": [
    "# a = open('infer_df_valid_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T15:04:12.545141Z",
     "iopub.status.busy": "2022-02-13T15:04:12.544633Z",
     "iopub.status.idle": "2022-02-13T15:04:12.612786Z",
     "shell.execute_reply": "2022-02-13T15:04:12.612082Z",
     "shell.execute_reply.started": "2022-02-13T15:04:12.545105Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(generate, \n",
    "                                         output_signature=((tf.TensorSpec(shape=(1,), dtype=tf.float64),\n",
    "                                                            tf.TensorSpec(shape=(1,), dtype=tf.int32),\n",
    "                                                            tf.TensorSpec(shape=(50,), dtype=tf.int32),\n",
    "                                                            tf.TensorSpec(shape=(1,), dtype=tf.int32)),\n",
    "                                                            tf.TensorSpec(shape=(target_size), dtype=tf.float64)\n",
    "                                                           ),\n",
    "                                         args=['train_dataset.csv']).batch(128).prefetch(5)\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_generator(generate, \n",
    "                                         output_signature=((tf.TensorSpec(shape=(1,), dtype=tf.float64),\n",
    "                                                            tf.TensorSpec(shape=(1,), dtype=tf.int32),\n",
    "                                                            tf.TensorSpec(shape=(50,), dtype=tf.int32),\n",
    "                                                            tf.TensorSpec(shape=(1,), dtype=tf.int32)),\n",
    "                                                            tf.TensorSpec(shape=(target_size), dtype=tf.float64)\n",
    "                                                           ),\n",
    "                                         args=['test_dataset.csv']).batch(128)\n",
    "\n",
    "dataset_valid = tf.data.Dataset.from_generator(generate, \n",
    "                                         output_signature=(tf.TensorSpec(shape=(1,), dtype=tf.float64),\n",
    "                                                            tf.TensorSpec(shape=(1,), dtype=tf.int32),\n",
    "                                                            tf.TensorSpec(shape=(50,), dtype=tf.int32),\n",
    "                                                          tf.TensorSpec(shape=(1,), dtype=tf.int32)),\n",
    "                                         args=['infer_df_valid_dataset.csv', True]).batch(200)\n",
    "\n",
    "# dataset_submission = tf.data.Dataset.from_generator(generate, \n",
    "#                                          output_signature=(tf.TensorSpec(shape=(1,), dtype=tf.float64),\n",
    "#                                                             tf.TensorSpec(shape=(1,), dtype=tf.int32),\n",
    "#                                                             tf.TensorSpec(shape=(1,), dtype=tf.string)),\n",
    "#                                          args=['submission_dataset.csv', True]).batch(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:38:13.437458Z",
     "iopub.status.busy": "2022-02-13T07:38:13.437208Z",
     "iopub.status.idle": "2022-02-13T07:38:13.468258Z",
     "shell.execute_reply": "2022-02-13T07:38:13.467511Z",
     "shell.execute_reply.started": "2022-02-13T07:38:13.437422Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_submission = tf.data.Dataset.from_generator(generate, \n",
    "#                                          output_signature=(tf.TensorSpec(shape=(1,), dtype=tf.float64),\n",
    "#                                                             tf.TensorSpec(shape=(1,), dtype=tf.int32),\n",
    "#                                                             tf.TensorSpec(shape=(1,), dtype=tf.string)),\n",
    "#                                          args=['submission_dataset.csv', True]).batch(1000).prefetch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:57:57.701594Z",
     "iopub.status.busy": "2022-02-13T09:57:57.701317Z",
     "iopub.status.idle": "2022-02-13T09:57:57.715418Z",
     "shell.execute_reply": "2022-02-13T09:57:57.714393Z",
     "shell.execute_reply.started": "2022-02-13T09:57:57.701557Z"
    }
   },
   "outputs": [],
   "source": [
    "# texts = dataset.map(lambda x, y: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:50:38.633326Z",
     "iopub.status.busy": "2022-02-13T14:50:38.633080Z",
     "iopub.status.idle": "2022-02-13T14:50:38.637929Z",
     "shell.execute_reply": "2022-02-13T14:50:38.637215Z",
     "shell.execute_reply.started": "2022-02-13T14:50:38.633298Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import TextVectorization\n",
    "# import string\n",
    "# import re\n",
    "\n",
    "\n",
    "# def custom_standardization(input_data):\n",
    "#     lowercase = tf.strings.lower(input_data)\n",
    "#     text = tf.strings.regex_replace(lowercase, \"##\", \" #SEP# \")\n",
    "#     return text\n",
    "\n",
    "\n",
    "# max_features = 50000\n",
    "# sequence_length = 100\n",
    "\n",
    "# vectorize_layer = TextVectorization(\n",
    "#     standardize=custom_standardization,\n",
    "#     max_tokens=max_features,\n",
    "#     output_mode=\"int\",\n",
    "#     output_sequence_length=sequence_length\n",
    "# )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:50:41.984525Z",
     "iopub.status.busy": "2022-02-13T14:50:41.984070Z",
     "iopub.status.idle": "2022-02-13T14:50:41.988246Z",
     "shell.execute_reply": "2022-02-13T14:50:41.987573Z",
     "shell.execute_reply.started": "2022-02-13T14:50:41.984489Z"
    }
   },
   "outputs": [],
   "source": [
    "# vectorize_layer.adapt(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T15:03:56.986673Z",
     "iopub.status.busy": "2022-02-13T15:03:56.985976Z",
     "iopub.status.idle": "2022-02-13T15:03:56.990167Z",
     "shell.execute_reply": "2022-02-13T15:03:56.989312Z",
     "shell.execute_reply.started": "2022-02-13T15:03:56.986639Z"
    }
   },
   "outputs": [],
   "source": [
    "g = generate('train_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T15:04:08.754974Z",
     "iopub.status.busy": "2022-02-13T15:04:08.754585Z",
     "iopub.status.idle": "2022-02-13T15:04:08.770057Z",
     "shell.execute_reply": "2022-02-13T15:04:08.769433Z",
     "shell.execute_reply.started": "2022-02-13T15:04:08.754939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(1,), dtype=float64, numpy=array([37.])>,\n",
       "  <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3,\n",
       "         4, 2, 5, 6, 7, 8], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(1,), dtype=int32, numpy=array([7], dtype=int32)>),\n",
       " <tf.Tensor: shape=(19898,), dtype=float64, numpy=array([0., 0., 0., ..., 0., 0., 0.])>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T07:41:50.821444Z",
     "iopub.status.busy": "2022-02-13T07:41:50.821207Z",
     "iopub.status.idle": "2022-02-13T07:41:50.953626Z",
     "shell.execute_reply": "2022-02-13T07:41:50.952874Z",
     "shell.execute_reply.started": "2022-02-13T07:41:50.821411Z"
    }
   },
   "outputs": [],
   "source": [
    "# import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T15:11:47.533009Z",
     "iopub.status.busy": "2022-02-13T15:11:47.532729Z",
     "iopub.status.idle": "2022-02-13T15:11:47.644639Z",
     "shell.execute_reply": "2022-02-13T15:11:47.643806Z",
     "shell.execute_reply.started": "2022-02-13T15:11:47.532983Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs_age = tf.keras.layers.Input(shape=(1,), dtype=tf.float64)\n",
    "inputs_postal = tf.keras.layers.Input(shape=(1,), dtype=tf.int32)\n",
    "inputs_history = tf.keras.layers.Input(shape=(50,), dtype=tf.int32)\n",
    "inputs_season = tf.keras.layers.Input(shape=(1,), dtype=tf.int32)\n",
    "\n",
    "# history = vectorize_layer(inputs_history)\n",
    "\n",
    "embeddings_postal = tf.keras.layers.Embedding(input_dim=len(post2id), output_dim=20)(inputs_postal )\n",
    "embeddings_season = tf.keras.layers.Embedding(input_dim=12, output_dim=5)(inputs_season )\n",
    "embeddings_history = tf.keras.layers.Embedding(input_dim=len(prod2id), output_dim=100)(inputs_history)\n",
    "\n",
    "dense_age = tf.keras.layers.Dense(10, activation='relu')(inputs_age)\n",
    "dense_age_flatten = tf.keras.layers.Flatten()(dense_age)\n",
    "\n",
    "dense_post = tf.keras.layers.Dense(10, activation='relu')(embeddings_postal)\n",
    "dense_post_flatten = tf.keras.layers.Flatten()(dense_post)\n",
    "\n",
    "dense_season = tf.keras.layers.Dense(10, activation='relu')(embeddings_season)\n",
    "dense_season_flatten = tf.keras.layers.Flatten()(dense_season)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# mean = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x,  axis=1))(embeddings_history)\n",
    "lstm_history = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512, return_sequences=False))(embeddings_history)\n",
    "# conv1 = tf.keras.layers.Conv1D(kernel_size=7, filters=128, strides=1, activation='relu')(embeddings_history)\n",
    "# conv2 = tf.keras.layers.Conv1D(kernel_size=5, filters=128, strides=1, activation='relu')(conv1)\n",
    "# conv3 = tf.keras.layers.Conv1D(kernel_size=3, filters=128, strides=1, activation='relu')(conv2)\n",
    "# pool = tf.keras.layers.AveragePooling1D()(conv3)\n",
    "# flat = tf.keras.layers.Flatten()(pool)\n",
    "\n",
    "\n",
    "# convs = []\n",
    "\n",
    "# for ks in [3,4,5,7,10,20]:\n",
    "#     conv1 = tf.keras.layers.Conv1D(kernel_size=ks, filters=256, padding='same', activation='relu',\n",
    "#                                    strides=1)(embeddings_history)\n",
    "#     conv2 = tf.keras.layers.Conv1D(kernel_size=ks, filters=256, padding='same',strides=1, \n",
    "#                                   activation='relu')(conv1)\n",
    "#     convs.append(conv2)\n",
    "\n",
    "\n",
    "# concat_convs = tf.keras.layers.concatenate(convs, axis=2)\n",
    "\n",
    "# conv_global = tf.keras.layers.Conv1D(kernel_size=5, filters=256, strides=1, activation='relu')(concat_convs)\n",
    "# flatten_conv = tf.keras.layers.Flatten()(conv_global)\n",
    "\n",
    "\n",
    "dense_general = tf.keras.layers.Dense(100, activation='relu')(lstm_history)\n",
    "\n",
    "concat = tf.keras.layers.concatenate([\n",
    "                                      dense_age_flatten,\n",
    "                                      dense_post_flatten, \n",
    "                                      dense_general,\n",
    "                                      dense_season_flatten,\n",
    "#                                       flatten_conv\n",
    "#                                       flat\n",
    "                                     ], axis=-1)\n",
    "\n",
    "\n",
    "output = tf.keras.layers.Dense(target_size, activation='relu')(concat)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs_age, inputs_postal, inputs_history, inputs_season], \n",
    "                       outputs=output)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.CosineSimilarity(),\n",
    "#               loss=tfa.losses.()\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T15:11:48.139894Z",
     "iopub.status.busy": "2022-02-13T15:11:48.139203Z",
     "iopub.status.idle": "2022-02-13T15:11:48.155388Z",
     "shell.execute_reply": "2022-02-13T15:11:48.154571Z",
     "shell.execute_reply.started": "2022-02-13T15:11:48.139856Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_113 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_114 (InputLayer)         [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " input_115 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_112 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_81 (Embedding)       (None, 1, 20)        390280      ['input_113[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_83 (Embedding)       (None, 50, 100)      1992300     ['input_114[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_82 (Embedding)       (None, 1, 5)         60          ['input_115[0][0]']              \n",
      "                                                                                                  \n",
      " dense_126 (Dense)              (None, 10)           20          ['input_112[0][0]']              \n",
      "                                                                                                  \n",
      " dense_127 (Dense)              (None, 1, 10)        210         ['embedding_81[0][0]']           \n",
      "                                                                                                  \n",
      " bidirectional_11 (Bidirectiona  (None, 1024)        1886208     ['embedding_83[0][0]']           \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " dense_128 (Dense)              (None, 1, 10)        60          ['embedding_82[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_77 (Flatten)           (None, 10)           0           ['dense_126[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_78 (Flatten)           (None, 10)           0           ['dense_127[0][0]']              \n",
      "                                                                                                  \n",
      " dense_129 (Dense)              (None, 100)          102500      ['bidirectional_11[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_79 (Flatten)           (None, 10)           0           ['dense_128[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 130)          0           ['flatten_77[0][0]',             \n",
      "                                                                  'flatten_78[0][0]',             \n",
      "                                                                  'dense_129[0][0]',              \n",
      "                                                                  'flatten_79[0][0]']             \n",
      "                                                                                                  \n",
      " dense_130 (Dense)              (None, 19923)        2609913     ['concatenate_29[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,981,551\n",
      "Trainable params: 6,981,551\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T15:11:48.681123Z",
     "iopub.status.busy": "2022-02-13T15:11:48.680838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5148/5148 [==============================] - 564s 109ms/step - loss: -0.0098 - val_loss: -0.0105\n",
      "Epoch 2/10\n",
      "5148/5148 [==============================] - 561s 109ms/step - loss: -0.0112 - val_loss: -0.0113\n",
      "Epoch 3/10\n",
      "5148/5148 [==============================] - ETA: 0s - loss: -0.0134"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [281]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1420\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1407\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1408\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1409\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1418\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1419\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1420\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   1433\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1716\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1715\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1716\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1717\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1718\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(dataset, validation_data=dataset_test, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 9s 98ms/step - loss: -0.0081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.00806447770446539"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T12:13:39.897614Z",
     "iopub.status.busy": "2022-02-13T12:13:39.897112Z",
     "iopub.status.idle": "2022-02-13T12:18:04.629853Z",
     "shell.execute_reply": "2022-02-13T12:18:04.629065Z",
     "shell.execute_reply.started": "2022-02-13T12:13:39.897567Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_articles = []\n",
    "for batch in dataset_valid:\n",
    "    preds = model.predict_on_batch(batch)\n",
    "    top_12 = preds.argsort(1)[:, :-13:-1]\n",
    "    \n",
    "    for i in range(preds.shape[0]):\n",
    "        filtered_top_12 = '##'.join([id2prod[p] for p in top_12[i] if preds[i][p] > 0.05])\n",
    "        pred_articles.append(filtered_top_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T12:18:04.632474Z",
     "iopub.status.busy": "2022-02-13T12:18:04.632225Z",
     "iopub.status.idle": "2022-02-13T12:18:04.641478Z",
     "shell.execute_reply": "2022-02-13T12:18:04.640544Z",
     "shell.execute_reply.started": "2022-02-13T12:18:04.632441Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_dataset['prediction'] = pred_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T12:18:04.643502Z",
     "iopub.status.busy": "2022-02-13T12:18:04.643216Z",
     "iopub.status.idle": "2022-02-13T12:18:04.660085Z",
     "shell.execute_reply": "2022-02-13T12:18:04.659428Z",
     "shell.execute_reply.started": "2022-02-13T12:18:04.643467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>post</th>\n",
       "      <th>history</th>\n",
       "      <th>target</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>43cbf97df3d118b937551fb21a08d513bfb2e58223315f...</td>\n",
       "      <td>Jennifer (1)##Cat Tee##Pamela Tee.##Kirsten##M...</td>\n",
       "      <td>Brit Baby Tee</td>\n",
       "      <td>9</td>\n",
       "      <td>00039306476aaf41a07fed942884f16b30abfa83a2a8be...</td>\n",
       "      <td>Pluto RW slacks (1)##Milk RW slack##Jade HW Sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>d647e4ede3d0eb4ce0750440a110350b5f4c758165d89d...</td>\n",
       "      <td>Blake Sandal##Svea Cropped Tank##Connie Cut Ou...</td>\n",
       "      <td>DONNA DENIM SKIRT</td>\n",
       "      <td>9</td>\n",
       "      <td>0003e867a930d0d6842f923d6ba7c9b77aba33fe2a0fbf...</td>\n",
       "      <td>Jade HW Skinny Denim TRS##RICHIE HOOD##Timeles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>72afbb92c0200628bfa8f983c241eb0dc14e107f87d95b...</td>\n",
       "      <td>H2 Carnation solid##Bowie jumpsuit##Skinny H.W...</td>\n",
       "      <td>Skinny H.W Ankle Festive##Maja cargo Slim HW D...</td>\n",
       "      <td>9</td>\n",
       "      <td>000493dd9fc463df1acc2081450c9e75ef8e87d5dd17ed...</td>\n",
       "      <td>Jade HW Skinny Denim TRS##Superwoman Superpush...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>ed323346483de9f9b9ac7d73d34e0c87b5946d09da3b07...</td>\n",
       "      <td></td>\n",
       "      <td>Herbal Hood -TVP</td>\n",
       "      <td>9</td>\n",
       "      <td>000525e3fe01600d717da8423643a8303390a055c578ed...</td>\n",
       "      <td>Jade HW Skinny Denim TRS##Curvy Jeggings HW An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>3119ea10ffe5ac3419b9127589a61b33e1ae38ecbb997b...</td>\n",
       "      <td>Bobo##W YODA KNIT OL OFFER##Jafar##Peggy Trous...</td>\n",
       "      <td>Mini me Tassle fur##Chilly padded coat##Highwa...</td>\n",
       "      <td>9</td>\n",
       "      <td>00077dbd5c4a4991e092e63893ccf29294a9d5c46e8501...</td>\n",
       "      <td>Antonia heavy t-shirt##Jen tee##Lemon HW##Bail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68979</th>\n",
       "      <td>24</td>\n",
       "      <td>ef06cc9c740983fed082a8cc961cbcb4db1b40c8a2a369...</td>\n",
       "      <td>Twelve top##Nord tee##Frida Printed Sweater##D...</td>\n",
       "      <td>Barrista cardigan##Bama1</td>\n",
       "      <td>9</td>\n",
       "      <td>fffa67737587e52ff1afa9c7c6490b5eb7acbc439fe82b...</td>\n",
       "      <td>Jade HW Skinny Denim TRS##Jen tee##Milk RW sla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68980</th>\n",
       "      <td>50</td>\n",
       "      <td>ce29e6932c6263c659e14c0f170fd8d2c332fbbae00144...</td>\n",
       "      <td>Heart LS##W YODA KNIT OL OFFER##Scallop 5p Soc...</td>\n",
       "      <td>Sunspot Seamless Crop Top##Acai seamless bra C...</td>\n",
       "      <td>9</td>\n",
       "      <td>fffa7d7799eb390a76308454cbdd76e473d65b1497fbe4...</td>\n",
       "      <td>Timeless Midrise Brief##RICHIE HOOD##Shake it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68981</th>\n",
       "      <td>25</td>\n",
       "      <td>102183de22c6110db8e6e9b520a7aaab65c0cee1c5ff5a...</td>\n",
       "      <td>Curvy Jeggings HW Ankle##Michaela wallet big##...</td>\n",
       "      <td>Glamping##Kelso##Becka hoodie##Kelso##ED Barab...</td>\n",
       "      <td>9</td>\n",
       "      <td>fffae8eb3a282d8c43c77dd2ca0621703b71e90904dfde...</td>\n",
       "      <td>Jade HW Skinny Denim TRS##Bowie##Push Up Jeggi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68982</th>\n",
       "      <td>45</td>\n",
       "      <td>ed6e0192fc1235342b0211e38e95d81d146fa09b7e0e47...</td>\n",
       "      <td>SKINNY Knit 89##Skinny Biker Trash##JOGGER Kni...</td>\n",
       "      <td>DeLuca pull on TVP RW##ESSENTIAL YOKO ROLLER NECK</td>\n",
       "      <td>9</td>\n",
       "      <td>fffd870c6324ad3bda24e4d6aeae221c199479086bfdfd...</td>\n",
       "      <td>Jade HW Skinny Denim TRS##Timeless Midrise Bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68983</th>\n",
       "      <td>29</td>\n",
       "      <td>47258851e6f73dd2583ef4775814f9b88e43a9e2741c64...</td>\n",
       "      <td>Winnie top##Winnie top##Marseille Jacket##Mars...</td>\n",
       "      <td>Venice</td>\n",
       "      <td>9</td>\n",
       "      <td>fffef3b6b73545df065b521e19f64bf6fe93bfd450ab20...</td>\n",
       "      <td>RICHIE HOOD##Pluto RW slacks (1)##Timeless Mid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68984 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                                               post  \\\n",
       "0       27  43cbf97df3d118b937551fb21a08d513bfb2e58223315f...   \n",
       "1       33  d647e4ede3d0eb4ce0750440a110350b5f4c758165d89d...   \n",
       "2       29  72afbb92c0200628bfa8f983c241eb0dc14e107f87d95b...   \n",
       "3       25  ed323346483de9f9b9ac7d73d34e0c87b5946d09da3b07...   \n",
       "4       23  3119ea10ffe5ac3419b9127589a61b33e1ae38ecbb997b...   \n",
       "...    ...                                                ...   \n",
       "68979   24  ef06cc9c740983fed082a8cc961cbcb4db1b40c8a2a369...   \n",
       "68980   50  ce29e6932c6263c659e14c0f170fd8d2c332fbbae00144...   \n",
       "68981   25  102183de22c6110db8e6e9b520a7aaab65c0cee1c5ff5a...   \n",
       "68982   45  ed6e0192fc1235342b0211e38e95d81d146fa09b7e0e47...   \n",
       "68983   29  47258851e6f73dd2583ef4775814f9b88e43a9e2741c64...   \n",
       "\n",
       "                                                 history  \\\n",
       "0      Jennifer (1)##Cat Tee##Pamela Tee.##Kirsten##M...   \n",
       "1      Blake Sandal##Svea Cropped Tank##Connie Cut Ou...   \n",
       "2      H2 Carnation solid##Bowie jumpsuit##Skinny H.W...   \n",
       "3                                                          \n",
       "4      Bobo##W YODA KNIT OL OFFER##Jafar##Peggy Trous...   \n",
       "...                                                  ...   \n",
       "68979  Twelve top##Nord tee##Frida Printed Sweater##D...   \n",
       "68980  Heart LS##W YODA KNIT OL OFFER##Scallop 5p Soc...   \n",
       "68981  Curvy Jeggings HW Ankle##Michaela wallet big##...   \n",
       "68982  SKINNY Knit 89##Skinny Biker Trash##JOGGER Kni...   \n",
       "68983  Winnie top##Winnie top##Marseille Jacket##Mars...   \n",
       "\n",
       "                                                  target  t_dat  \\\n",
       "0                                          Brit Baby Tee      9   \n",
       "1                                      DONNA DENIM SKIRT      9   \n",
       "2      Skinny H.W Ankle Festive##Maja cargo Slim HW D...      9   \n",
       "3                                       Herbal Hood -TVP      9   \n",
       "4      Mini me Tassle fur##Chilly padded coat##Highwa...      9   \n",
       "...                                                  ...    ...   \n",
       "68979                           Barrista cardigan##Bama1      9   \n",
       "68980  Sunspot Seamless Crop Top##Acai seamless bra C...      9   \n",
       "68981  Glamping##Kelso##Becka hoodie##Kelso##ED Barab...      9   \n",
       "68982  DeLuca pull on TVP RW##ESSENTIAL YOKO ROLLER NECK      9   \n",
       "68983                                             Venice      9   \n",
       "\n",
       "                                             customer_id  \\\n",
       "0      00039306476aaf41a07fed942884f16b30abfa83a2a8be...   \n",
       "1      0003e867a930d0d6842f923d6ba7c9b77aba33fe2a0fbf...   \n",
       "2      000493dd9fc463df1acc2081450c9e75ef8e87d5dd17ed...   \n",
       "3      000525e3fe01600d717da8423643a8303390a055c578ed...   \n",
       "4      00077dbd5c4a4991e092e63893ccf29294a9d5c46e8501...   \n",
       "...                                                  ...   \n",
       "68979  fffa67737587e52ff1afa9c7c6490b5eb7acbc439fe82b...   \n",
       "68980  fffa7d7799eb390a76308454cbdd76e473d65b1497fbe4...   \n",
       "68981  fffae8eb3a282d8c43c77dd2ca0621703b71e90904dfde...   \n",
       "68982  fffd870c6324ad3bda24e4d6aeae221c199479086bfdfd...   \n",
       "68983  fffef3b6b73545df065b521e19f64bf6fe93bfd450ab20...   \n",
       "\n",
       "                                              prediction  \n",
       "0      Pluto RW slacks (1)##Milk RW slack##Jade HW Sk...  \n",
       "1      Jade HW Skinny Denim TRS##RICHIE HOOD##Timeles...  \n",
       "2      Jade HW Skinny Denim TRS##Superwoman Superpush...  \n",
       "3      Jade HW Skinny Denim TRS##Curvy Jeggings HW An...  \n",
       "4      Antonia heavy t-shirt##Jen tee##Lemon HW##Bail...  \n",
       "...                                                  ...  \n",
       "68979  Jade HW Skinny Denim TRS##Jen tee##Milk RW sla...  \n",
       "68980  Timeless Midrise Brief##RICHIE HOOD##Shake it ...  \n",
       "68981  Jade HW Skinny Denim TRS##Bowie##Push Up Jeggi...  \n",
       "68982  Jade HW Skinny Denim TRS##Timeless Midrise Bri...  \n",
       "68983  RICHIE HOOD##Pluto RW slacks (1)##Timeless Mid...  \n",
       "\n",
       "[68984 rows x 7 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T12:18:13.654338Z",
     "iopub.status.busy": "2022-02-13T12:18:13.653930Z",
     "iopub.status.idle": "2022-02-13T12:18:14.044442Z",
     "shell.execute_reply": "2022-02-13T12:18:14.043730Z",
     "shell.execute_reply.started": "2022-02-13T12:18:13.654298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010450144905261393"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(valid_dataset['target'].str.split(\"##\"), valid_dataset['prediction'].str.split('##'), 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-12T16:27:36.100412Z",
     "iopub.status.busy": "2022-02-12T16:27:36.099645Z",
     "iopub.status.idle": "2022-02-12T16:29:36.399563Z",
     "shell.execute_reply": "2022-02-12T16:29:36.397322Z",
     "shell.execute_reply.started": "2022-02-12T16:27:36.10037Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_articles_sub = []\n",
    "for ij, batch in enumerate(dataset_submission):\n",
    "    if not (ij+1) % 100:\n",
    "        print(ij * 500)\n",
    "    preds = model.predict_on_batch(batch)\n",
    "    top_12 = preds.argsort(1)[:, :-13:-1]\n",
    "    \n",
    "    for i in range(preds.shape[0]):\n",
    "        filtered_top_12 = ' '.join([id2prod[p] for p in top_12[i] if preds[i][p] > 0.30])\n",
    "        pred_articles_sub.append(filtered_top_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-12T16:14:56.652001Z",
     "iopub.status.idle": "2022-02-12T16:14:56.652613Z",
     "shell.execute_reply": "2022-02-12T16:14:56.652382Z",
     "shell.execute_reply.started": "2022-02-12T16:14:56.652353Z"
    }
   },
   "outputs": [],
   "source": [
    "submision_df['prediction'] = pred_articles_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-12T16:11:14.760539Z",
     "iopub.status.idle": "2022-02-12T16:11:14.761407Z",
     "shell.execute_reply": "2022-02-12T16:11:14.761184Z",
     "shell.execute_reply.started": "2022-02-12T16:11:14.761157Z"
    }
   },
   "outputs": [],
   "source": [
    "submision_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-12T16:11:14.762529Z",
     "iopub.status.idle": "2022-02-12T16:11:14.763426Z",
     "shell.execute_reply": "2022-02-12T16:11:14.763197Z",
     "shell.execute_reply.started": "2022-02-12T16:11:14.76317Z"
    }
   },
   "outputs": [],
   "source": [
    "submision_df[['customer_id', 'prediction']].to_csv(\"submission.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
