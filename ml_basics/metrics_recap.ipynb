{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcbee4ef",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b39ce2",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f0617a",
   "metadata": {},
   "source": [
    "Accuracy is the percentage of correct answers. It is not a good metric when there is a class imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb1e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6ba6763",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f10e2",
   "metadata": {},
   "source": [
    "Precision is the percentage of objects correctly labeled as positive. \n",
    "\n",
    "In order to compute precision the number of true posives and the number of false positives need to be estimated. True positives are objects that were labeled positive and are actually positive. False positives are objects that were labelled positive but are actually negative (it is type 1 error).\n",
    "\n",
    "Precision is TP divided by TP + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f1358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP / TP + FP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268893c",
   "metadata": {},
   "source": [
    "Precision leans towards risk aversion. A model can label only a small fraction of positive objects as positive and stil get a high precision score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bbbf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcc62c6f",
   "metadata": {},
   "source": [
    "####  Increasing the threshold does not guarantee that precision will increase! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e80b20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c952cab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnefedov/.pyenv/versions/3.7.2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mnefedov/.pyenv/versions/3.7.2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "true = np.array([1, 1, 1, 1, 0, 0, 0, 0])\n",
    "pred = np.array([0.51, 0.4, 0.6, 0.98, 0.1, 0.05, 0.41, 0.44])\n",
    "\n",
    "precs = []\n",
    "for i in range(100):\n",
    "    precs.append(precision_score(true, (pred>i/100).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9106dd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x136660470>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(100)), precs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb9346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42fcff82",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e525a4a",
   "metadata": {},
   "source": [
    "Recall is the percentage of positive objects labelled as positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655e4955",
   "metadata": {},
   "source": [
    "In order to compute recall the number of true posives and the number of false negatives need to be estimated. True positives are objects that were labeled positive and are actually positive. False negatives are objects that were labelled negative but are actually positive (it is type 2 error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5cf409",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = TP / TP + FN\n",
    "\n",
    "recall == sensitivity == True_Positive_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383f797",
   "metadata": {},
   "source": [
    "Recall leans towards risk taking. A model can label everything as positive and get a high score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a679d",
   "metadata": {},
   "source": [
    "### F-measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d344c1",
   "metadata": {},
   "source": [
    "F-measure aims to balance Precision and Recall. There are different variants of F-measure, depending on what is more important.\n",
    "\n",
    "F1-measure equally values precision and recall. It is a harmonic means of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40847f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2 * (Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92c72e",
   "metadata": {},
   "source": [
    "Beta F-measure is a more general metric with a tunable parameter beta which reflects the importance of recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304e3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_beta = (1+beta**2) * (Precision * Recall) / ((beta**2 * Precision) + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953faf1",
   "metadata": {},
   "source": [
    "If beta == 2, recall is twicely more important, if beta == 0.5 precision is twicely more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebca20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5888b5ec",
   "metadata": {},
   "source": [
    "### Micro-, macro-averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8b4dd",
   "metadata": {},
   "source": [
    "Precision, Recall and F-measure are computed for a single class. In order to get an average score we can either average all the individial precisions, recalls, and f-measures or aggregate a total number of TP, FP and FN and compute a general P, R and F from them.\n",
    "\n",
    "First approach is called macro averaging. The second one - micro averaging.\n",
    "\n",
    "Micro averaging is dependent on class balance, it leans towards major classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0ce5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49410a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f1ce525",
   "metadata": {},
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0693e234",
   "metadata": {},
   "source": [
    "ROC curve is a plot of True positive rate against False Positive Rate over a range of thresholds. TPR is recall (TP/TP+FN). FPR is computed by dividing the number of False positive by the number of False Positives plus the number of True Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(thresholds):\n",
    "    TPR = TP/TP+FN\n",
    "    FPR = FP/FP+TN\n",
    "    plot(TPR, FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c99ad6c",
   "metadata": {},
   "source": [
    "## ROC-AUC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed46f2c1",
   "metadata": {},
   "source": [
    "AUC is the area under the ROC curve. It is computed using trapezoidal rule??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448ec13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aefffec3",
   "metadata": {},
   "source": [
    "# Specificity  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4618b31f",
   "metadata": {},
   "source": [
    "Specificity is a True Negative Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f421391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TNR = 1 - FPR\n",
    "TNR = TN/TN + FP\n",
    "FPR = FP/FP + TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a89a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05213aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27c61267",
   "metadata": {},
   "source": [
    "# LIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cf19ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7086b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1df227e",
   "metadata": {},
   "source": [
    "## Gini "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b422a6c",
   "metadata": {},
   "source": [
    "(2 * ROC_AUC) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77451a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dac7b2af",
   "metadata": {},
   "source": [
    "## Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a156da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dfacf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27df33f5",
   "metadata": {},
   "source": [
    "# Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE, MSE, RMSE, MAPE, R_squared, msle, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
