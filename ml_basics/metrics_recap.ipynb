{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcbee4ef",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b39ce2",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f0617a",
   "metadata": {},
   "source": [
    "Accuracy is the percentage of correct answers. It is not a good metric when there is a class imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb1e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6ba6763",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f10e2",
   "metadata": {},
   "source": [
    "Precision is the percentage of objects correctly labeled as positive. \n",
    "\n",
    "In order to compute precision the number of true posives and the number of false positives need to be estimated. True positives are objects that were labeled positive and are actually positive. False positives are objects that were labelled positive but are actually negative (it is type 1 error).\n",
    "\n",
    "Precision is TP divided by TP + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f1358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP / TP + FP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268893c",
   "metadata": {},
   "source": [
    "Precision leans towards risk aversion. A model can label only a small fraction of positive objects as positive and stil get a high precision score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fcff82",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e525a4a",
   "metadata": {},
   "source": [
    "Recall is the percentage of positive objects labelled as positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655e4955",
   "metadata": {},
   "source": [
    "In order to compute recall the number of true posives and the number of false negatives need to be estimated. True positives are objects that were labeled positive and are actually positive. False negatives are objects that were labelled negative but are actually positive (it is type 2 error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5cf409",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = TP / TP + FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383f797",
   "metadata": {},
   "source": [
    "Recall leans towards risk taking. A model can label everything as positive and get a high score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a679d",
   "metadata": {},
   "source": [
    "### F-measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d344c1",
   "metadata": {},
   "source": [
    "F-measure aims to balance Precision and Recall. There are different variants of F-measure, depending on what is more important.\n",
    "\n",
    "F1-measure equally values precision and recall. It is a harmonic means of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40847f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2 * (Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92c72e",
   "metadata": {},
   "source": [
    "Beta F-measure is a more general metric with a tunable parameter beta which reflects the importance of recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304e3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_beta = (1+beta**2) * (Precision * Recall) / ((beta**2 * Precision) + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953faf1",
   "metadata": {},
   "source": [
    "If beta == 2, recall is twicely more important, if beta == 0.5 precision is twicely more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebca20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5888b5ec",
   "metadata": {},
   "source": [
    "### Micro-, macro-averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8b4dd",
   "metadata": {},
   "source": [
    "Precision, Recall and F-measure are computed for a single class. In order to get an average score we can either average all the individial precisions, recalls, and f-measures or aggregate a total number of TP, FP and FN and compute a general P, R and F from them.\n",
    "\n",
    "First approach is called macro averaging. The second one - micro averaging.\n",
    "\n",
    "Micro averaging is dependent on class balance, it leans towards major classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0ce5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49410a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f1ce525",
   "metadata": {},
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0693e234",
   "metadata": {},
   "source": [
    "ROC curve is a plot of True positive rate against False Positive Rate over a range of thresholds. TPR is recall (TP/TP+FN). FPR is computed by dividing the number of False positive by the number of False Positives plus the number of True Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e7b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c99ad6c",
   "metadata": {},
   "source": [
    "## ROC-AUC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed46f2c1",
   "metadata": {},
   "source": [
    "AUC is the area under the ROC curve. It is computed using trapezoidal rule??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448ec13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1df227e",
   "metadata": {},
   "source": [
    "## Gini "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b422a6c",
   "metadata": {},
   "source": [
    "(2 * ROC_AUC) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77451a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dac7b2af",
   "metadata": {},
   "source": [
    "## Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a156da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dfacf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27df33f5",
   "metadata": {},
   "source": [
    "# Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE, MSE, RMSE, MAPE, R_squared, msle, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
