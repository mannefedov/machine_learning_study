{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error\nfrom tqdm.notebook import tqdm\nfrom collections import Counter\n\nwarnings.filterwarnings(\"ignore\")\nNUM_WORKERS = 4","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-24T14:18:06.870961Z","iopub.execute_input":"2021-09-24T14:18:06.871233Z","iopub.status.idle":"2021-09-24T14:18:07.773275Z","shell.execute_reply.started":"2021-09-24T14:18:06.871198Z","shell.execute_reply":"2021-09-24T14:18:07.772516Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"markdown","source":"### Load","metadata":{}},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/ventilator-pressure-prediction/\"\n\nsub = pd.read_csv(DATA_PATH + 'sample_submission.csv')\ndf_train = pd.read_csv(DATA_PATH + 'train.csv')\ndf_test = pd.read_csv(DATA_PATH + 'test.csv')\n\n\ndf_train = df_train[df_train['breath_id'] < 500].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T14:36:04.520212Z","iopub.execute_input":"2021-09-24T14:36:04.520483Z","iopub.status.idle":"2021-09-24T14:36:25.637557Z","shell.execute_reply.started":"2021-09-24T14:36:04.520453Z","shell.execute_reply":"2021-09-24T14:36:25.636818Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-24T14:36:25.639065Z","iopub.execute_input":"2021-09-24T14:36:25.639297Z","iopub.status.idle":"2021-09-24T14:36:25.645404Z","shell.execute_reply.started":"2021-09-24T14:36:25.639266Z","shell.execute_reply":"2021-09-24T14:36:25.644483Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"# df.sort_values(by='time_step').groupby('breath_id').agg(list)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T11:27:39.715845Z","iopub.execute_input":"2021-09-24T11:27:39.716625Z","iopub.status.idle":"2021-09-24T11:27:39.722198Z","shell.execute_reply.started":"2021-09-24T11:27:39.716583Z","shell.execute_reply":"2021-09-24T11:27:39.720825Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass VentilatorDataset(Dataset):\n    def __init__(self, df):\n        if \"pressure\" not in df.columns:\n            df['pressure'] = 0\n\n        self.df = df.groupby('breath_id').agg(list).reset_index()\n        \n        self.prepare_data()\n                \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def prepare_data(self):\n        self.pressures = np.array(self.df['pressure'].values.tolist())\n        \n        rs = np.array(self.df['R'].values.tolist())\n        cs = np.array(self.df['C'].values.tolist())\n        u_ins = np.array(self.df['u_in'].values.tolist())\n        \n#         self.u_outs = np.array(self.df['u_out'].values.tolist())\n        \n        self.inputs = np.concatenate([\n            rs[:, None], \n            cs[:, None], \n            u_ins[:, None], \n            np.cumsum(u_ins, 1)[:, None]\n        ], 1).transpose(0, 2, 1)\n\n    def __getitem__(self, idx):\n        data = {\n            \"input\": torch.tensor(self.inputs[idx], dtype=torch.float),\n#             \"u_out\": torch.tensor(self.u_outs[idx], dtype=torch.float),\n            \"p\": torch.tensor(self.pressures[idx], dtype=torch.float),\n        }\n        \n        return data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-24T14:18:21.429827Z","iopub.execute_input":"2021-09-24T14:18:21.430339Z","iopub.status.idle":"2021-09-24T14:18:21.441758Z","shell.execute_reply.started":"2021-09-24T14:18:21.430306Z","shell.execute_reply":"2021-09-24T14:18:21.441081Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset = VentilatorDataset(df)\ndataset[0]","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-24T14:18:21.443043Z","iopub.execute_input":"2021-09-24T14:18:21.443436Z","iopub.status.idle":"2021-09-24T14:18:21.562440Z","shell.execute_reply.started":"2021-09-24T14:18:21.443401Z","shell.execute_reply":"2021-09-24T14:18:21.561522Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Model\n- 2 Layer MLP\n- Bidirectional LSTM\n- Prediction dense layer","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import Tensor\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Transformer\nimport math\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\nclass PositionalEncoding(nn.Module):\n    def __init__(self,\n                 emb_size: int,\n                 dropout: float,\n                 maxlen: int = 150):\n        super(PositionalEncoding, self).__init__()\n        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n        pos_embedding = torch.zeros((maxlen, emb_size))\n        pos_embedding[:, 0::2] = torch.sin(pos * den)\n        pos_embedding[:, 1::2] = torch.cos(pos * den)\n        pos_embedding = pos_embedding.unsqueeze(-2)\n\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer('pos_embedding', pos_embedding)\n\n    def forward(self, token_embedding: Tensor):\n        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n\n# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size: int, emb_size):\n        super(TokenEmbedding, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size)\n        self.emb_size = emb_size\n\n    def forward(self, tokens: Tensor):\n        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n\n# Seq2Seq Network\nclass Seq2SeqTransformer(nn.Module):\n    def __init__(self,\n                 num_encoder_layers: int,\n                 num_decoder_layers: int,\n                 emb_size: int,\n                 nhead: int,\n                 dim_feedforward: int = 128,\n                 dropout: float = 0.1):\n        super(Seq2SeqTransformer, self).__init__()\n        self.transformer = Transformer(d_model=emb_size, \n                                       nhead=nhead,\n                                       num_encoder_layers=num_encoder_layers,\n                                       num_decoder_layers=num_decoder_layers,\n                                       dim_feedforward=dim_feedforward,\n                                       dropout=dropout)\n        self.generator = nn.Linear(emb_size, 1)\n        self.mlp_inp = nn.Sequential(\n            nn.Linear(4, emb_size, ),\n            nn.ReLU()\n        )\n        self.mlp_out = nn.Sequential(\n            nn.Linear(1, emb_size),\n            nn.ReLU()\n        )\n#         self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n#         self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n#         self.positional_encoding = PositionalEncoding(\n#             emb_size, dropout=dropout)\n\n    def forward(self,\n                src: Tensor,\n                tgt: Tensor,\n                src_mask: Tensor,\n                tgt_mask: Tensor,\n                src_padding_mask: Tensor,\n                tgt_padding_mask: Tensor,\n                memory_key_padding_mask: Tensor):\n        src_emb = self.mlp_inp(src).view(80, 64, 32)\n#         print('pos inp')\n\n        tgt_emb = self.mlp_out(tgt).view(79, 64, 32)\n    \n        \n#         print('pos dec')\n        outs = self.transformer(src_emb, tgt_emb, None, tgt_mask, None,\n                                None, tgt_padding_mask, memory_key_padding_mask)\n#         print('pos out')\n        x = self.generator(outs)\n#         print('gen')\n        return x\n\n    def encode(self, src: Tensor, src_mask: Tensor):\n        return self.transformer.encoder(src, src_mask)\n\n    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n        return self.transformer.decoder(tgt, memory,\n                          tgt_mask)\n# During training, we need a subsequent word mask that will prevent model to look into the future words when making predictions. We will also need masks to hide source and target padding tokens. Below, letâ€™s define a function that will take care of both.\n\ndef generate_square_subsequent_mask(sz):\n    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n    return mask\n\n\ndef create_mask(src, tgt):\n    src_seq_len = src.shape[0]\n    tgt_seq_len = tgt.shape[0]\n\n    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n\n    src_padding_mask = (src == -100).transpose(0, 1)\n    tgt_padding_mask = (tgt == -100).transpose(0, 1)\n    \n    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask","metadata":{"execution":{"iopub.status.busy":"2021-09-24T16:28:16.151753Z","iopub.execute_input":"2021-09-24T16:28:16.152043Z","iopub.status.idle":"2021-09-24T16:28:16.178176Z","shell.execute_reply.started":"2021-09-24T16:28:16.152009Z","shell.execute_reply":"2021-09-24T16:28:16.177434Z"},"trusted":true},"execution_count":311,"outputs":[]},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n\n\n# class RNNModel(nn.Module):\n#     def __init__(\n#         self,\n#         input_dim=4,\n#         lstm_dim=256,\n#         dense_dim=256,\n#         logit_dim=256,\n#         num_classes=1,\n#     ):\n#         super().__init__()\n\n#         self.mlp = nn.Sequential(\n#             nn.Linear(input_dim, dense_dim),\n#             nn.ReLU()\n#         )\n\n#         self.rnn = nn.LSTM(dense_dim, lstm_dim, batch_first=True)\n#         self.rnn_back = nn.LSTM(dense_dim, lstm_dim, batch_first=True)\n\n#         self.logits = nn.Sequential(\n# #             nn.Linear(lstm_dim * 2, logit_dim),\n# #             nn.ReLU(),\n# #             nn.Linear(logit_dim, num_classes),\n#             nn.Dropout(0.2),\n#             nn.Linear(lstm_dim * 2, num_classes),\n#         )\n\n#     def forward(self, x):\n#         features = self.mlp(x)\n#         features_backward = torch.flip(features, (1, ))\n        \n#         rnn_output, (h, *_) = self.rnn(features)\n#         rnn_output_backward, (h_backward, *_) = self.rnn_back(features_backward)\n        \n# #         h, h_backward = h.squeeze(0), h_backward.squeeze(0)\n        \n#         rnn_output_bidirectional = torch.cat([rnn_output, rnn_output_backward], 2)\n        \n        \n# #         features, _ = self.lstm(features)\n#         pred = self.logits(rnn_output_bidirectional)\n#         return pred","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-24T15:11:27.985097Z","iopub.execute_input":"2021-09-24T15:11:27.985668Z","iopub.status.idle":"2021-09-24T15:11:27.990703Z","shell.execute_reply.started":"2021-09-24T15:11:27.985632Z","shell.execute_reply":"2021-09-24T15:11:27.989487Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"### Utils","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport random\nimport numpy as np\n\n\ndef seed_everything(seed):\n    \"\"\"\n    Seeds basic parameters for reproductibility of results.\n\n    Args:\n        seed (int): Number of the seed.\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \n    \ndef count_parameters(model, all=False):\n    \"\"\"\n    Counts the parameters of a model.\n\n    Args:\n        model (torch model): Model to count the parameters of.\n        all (bool, optional):  Whether to count not trainable parameters. Defaults to False.\n\n    Returns:\n        int: Number of parameters.\n    \"\"\"\n    if all:\n        return sum(p.numel() for p in model.parameters())\n    else:\n        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n    \ndef worker_init_fn(worker_id):\n    \"\"\"\n    Handles PyTorch x Numpy seeding issues.\n\n    Args:\n    \n        worker_id (int): Id of the worker.\n    \"\"\"\n    np.random.seed(np.random.get_state()[1][0] + worker_id)\n    \n\ndef save_model_weights(model, filename, verbose=1, cp_folder=\"\"):\n    \"\"\"\n    Saves the weights of a PyTorch model.\n\n    Args:\n        model (torch model): Model to save the weights of.\n        filename (str): Name of the checkpoint.\n        verbose (int, optional): Whether to display infos. Defaults to 1.\n        cp_folder (str, optional): Folder to save to. Defaults to \"\".\n    \"\"\"\n    if verbose:\n        print(f\"\\n -> Saving weights to {os.path.join(cp_folder, filename)}\\n\")\n    torch.save(model.state_dict(), os.path.join(cp_folder, filename))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-24T15:11:29.010747Z","iopub.execute_input":"2021-09-24T15:11:29.011019Z","iopub.status.idle":"2021-09-24T15:11:29.020511Z","shell.execute_reply.started":"2021-09-24T15:11:29.010990Z","shell.execute_reply":"2021-09-24T15:11:29.019823Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"### Metric & Loss\n> The competition will be scored as the mean absolute error between the predicted and actual pressures during the inspiratory phase of each breath. The expiratory phase is not scored.","metadata":{}},{"cell_type":"markdown","source":"### Fit","metadata":{}},{"cell_type":"code","source":"inps = a['input'] # Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð±Ð°Ñ‚Ñ‡ Ð±Ñ‹Ð» Ð² ÐºÐ¾Ð½Ñ†Ðµ\nps = a['p'].unsqueeze(2) # Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð±Ð°Ñ‚Ñ‡ Ð±Ñ‹Ð» Ð² ÐºÐ¾Ð½Ñ†Ðµ\n\nps_input = ps[:, :-1]\n\n(inps_mask, ps_input_mask, \ninps_padding_mask, ps_input_padding_mask) = create_mask(inps.reshape(80, 64, 4), \n                                                        ps_input.reshape(79, 64, 1))\n# pred = model(inps, ps_input, inps_mask, ps_input_mask,\n#            inps_padding_mask, ps_input_padding_mask, inps_padding_mask)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T16:27:05.008106Z","iopub.execute_input":"2021-09-24T16:27:05.008828Z","iopub.status.idle":"2021-09-24T16:27:05.016890Z","shell.execute_reply.started":"2021-09-24T16:27:05.008792Z","shell.execute_reply":"2021-09-24T16:27:05.016126Z"},"trusted":true},"execution_count":307,"outputs":[]},{"cell_type":"code","source":"inps_mask.size(), inps_padding_mask.size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T16:27:07.004257Z","iopub.execute_input":"2021-09-24T16:27:07.005188Z","iopub.status.idle":"2021-09-24T16:27:07.012393Z","shell.execute_reply.started":"2021-09-24T16:27:07.005140Z","shell.execute_reply":"2021-09-24T16:27:07.011093Z"},"trusted":true},"execution_count":308,"outputs":[]},{"cell_type":"code","source":"mlp_out(ps_input).reshape(79, 64, 32).size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T16:14:05.613233Z","iopub.execute_input":"2021-09-24T16:14:05.613567Z","iopub.status.idle":"2021-09-24T16:14:05.622103Z","shell.execute_reply.started":"2021-09-24T16:14:05.613532Z","shell.execute_reply":"2021-09-24T16:14:05.621418Z"},"trusted":true},"execution_count":270,"outputs":[]},{"cell_type":"code","source":"mlp_inp = nn.Sequential(\n            nn.Linear(4, 32, ),\n            nn.ReLU()\n        )\nmlp_out = nn.Sequential(\n            nn.Linear(1, 32),\n            nn.ReLU()\n        )\n\ntransformer = Transformer(d_model=32, \n                                       nhead=8,\n                                       num_encoder_layers=2,\n                                       num_decoder_layers=2,\n                                       dim_feedforward=128,\n                                       dropout=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T16:07:29.510605Z","iopub.execute_input":"2021-09-24T16:07:29.511179Z","iopub.status.idle":"2021-09-24T16:07:29.530510Z","shell.execute_reply.started":"2021-09-24T16:07:29.511141Z","shell.execute_reply":"2021-09-24T16:07:29.529795Z"},"trusted":true},"execution_count":257,"outputs":[]},{"cell_type":"code","source":"inps_mask.size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T16:16:17.271119Z","iopub.execute_input":"2021-09-24T16:16:17.271807Z","iopub.status.idle":"2021-09-24T16:16:17.279032Z","shell.execute_reply.started":"2021-09-24T16:16:17.271772Z","shell.execute_reply":"2021-09-24T16:16:17.278234Z"},"trusted":true},"execution_count":277,"outputs":[]},{"cell_type":"code","source":"m = transformer.encoder(mlp_inp(inps).reshape(80, 64, 32), None)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T16:27:16.284986Z","iopub.execute_input":"2021-09-24T16:27:16.285710Z","iopub.status.idle":"2021-09-24T16:27:16.373318Z","shell.execute_reply.started":"2021-09-24T16:27:16.285674Z","shell.execute_reply":"2021-09-24T16:27:16.372605Z"},"trusted":true},"execution_count":309,"outputs":[]},{"cell_type":"code","source":"transformer.decoder(mlp_out(ps_input).reshape(79, 64, 32), m, ps_input_mask.to(torch.device('cpu'))).size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T16:27:30.373659Z","iopub.execute_input":"2021-09-24T16:27:30.373922Z","iopub.status.idle":"2021-09-24T16:27:30.526049Z","shell.execute_reply.started":"2021-09-24T16:27:30.373892Z","shell.execute_reply":"2021-09-24T16:27:30.525185Z"},"trusted":true},"execution_count":310,"outputs":[]},{"cell_type":"code","source":"inps.size(), ps_input.size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:56:11.003484Z","iopub.execute_input":"2021-09-24T15:56:11.003798Z","iopub.status.idle":"2021-09-24T15:56:11.009345Z","shell.execute_reply.started":"2021-09-24T15:56:11.003750Z","shell.execute_reply":"2021-09-24T15:56:11.008615Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"code","source":"ps_input.reshape(79, 64, 1).size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:57:00.578191Z","iopub.execute_input":"2021-09-24T15:57:00.578751Z","iopub.status.idle":"2021-09-24T15:57:00.584595Z","shell.execute_reply.started":"2021-09-24T15:57:00.578715Z","shell.execute_reply":"2021-09-24T15:57:00.583714Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:54:06.320593Z","iopub.execute_input":"2021-09-24T15:54:06.320864Z","iopub.status.idle":"2021-09-24T15:54:06.327615Z","shell.execute_reply.started":"2021-09-24T15:54:06.320836Z","shell.execute_reply":"2021-09-24T15:54:06.326729Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"ps_input_padding_mask.size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T16:01:09.100854Z","iopub.execute_input":"2021-09-24T16:01:09.101510Z","iopub.status.idle":"2021-09-24T16:01:09.106677Z","shell.execute_reply.started":"2021-09-24T16:01:09.101475Z","shell.execute_reply":"2021-09-24T16:01:09.106049Z"},"trusted":true},"execution_count":255,"outputs":[]},{"cell_type":"code","source":"mlp_out(ps_input).size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T16:22:27.074589Z","iopub.execute_input":"2021-09-24T16:22:27.074895Z","iopub.status.idle":"2021-09-24T16:22:27.087825Z","shell.execute_reply.started":"2021-09-24T16:22:27.074860Z","shell.execute_reply":"2021-09-24T16:22:27.086746Z"},"trusted":true},"execution_count":292,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlp_inp(inps.T).T[:-1, :].size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:20:41.126103Z","iopub.execute_input":"2021-09-24T15:20:41.126924Z","iopub.status.idle":"2021-09-24T15:20:41.133637Z","shell.execute_reply.started":"2021-09-24T15:20:41.126883Z","shell.execute_reply":"2021-09-24T15:20:41.132790Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"inps.size(), ps.size(), ps_input.size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T14:53:12.561305Z","iopub.execute_input":"2021-09-24T14:53:12.561822Z","iopub.status.idle":"2021-09-24T14:53:12.567329Z","shell.execute_reply.started":"2021-09-24T14:53:12.561786Z","shell.execute_reply":"2021-09-24T14:53:12.566679Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"ps[:, :-1].size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T14:50:29.298394Z","iopub.execute_input":"2021-09-24T14:50:29.298656Z","iopub.status.idle":"2021-09-24T14:50:29.307576Z","shell.execute_reply.started":"2021-09-24T14:50:29.298629Z","shell.execute_reply":"2021-09-24T14:50:29.306863Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"inps_mask","metadata":{"execution":{"iopub.status.busy":"2021-09-24T14:49:01.399826Z","iopub.execute_input":"2021-09-24T14:49:01.400597Z","iopub.status.idle":"2021-09-24T14:49:01.407046Z","shell.execute_reply.started":"2021-09-24T14:49:01.400559Z","shell.execute_reply":"2021-09-24T14:49:01.406192Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"import gc\nimport time\nimport torch\nimport numpy as np\nfrom torch.utils.data import DataLoader\nfrom transformers import get_linear_schedule_with_warmup\n\n\ndef fit(\n    model,\n    train_dataset,\n    val_dataset,\n    loss_name=\"L1Loss\",\n    optimizer=\"Adam\",\n    epochs=50,\n    batch_size=32,\n    val_bs=32,\n    warmup_prop=0.1,\n    lr=1e-3,\n    num_classes=1,\n    verbose=1,\n    first_epoch_eval=0,\n    device=\"cuda\"\n):\n    avg_val_loss = 0.\n\n    # Optimizer\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n    criterion = torch.nn.L1Loss()\n    criterion = criterion.to(device)\n    # Data loaders\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        drop_last=True,\n        num_workers=NUM_WORKERS,\n        pin_memory=True,\n        worker_init_fn=worker_init_fn\n    )\n\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=val_bs,\n        shuffle=False,\n        num_workers=NUM_WORKERS,\n        pin_memory=True,\n    )\n\n    # Loss\n#     loss_fct = getattr(torch.nn, loss_name)(reduction=\"none\")\n#     loss_fct = VentilatorLoss()\n\n    # Scheduler\n#     num_warmup_steps = int(warmup_prop * epochs * len(train_loader))\n#     num_training_steps = int(epochs * len(train_loader))\n#     scheduler = get_linear_schedule_with_warmup(\n#         optimizer, num_warmup_steps, num_training_steps\n#     )\n\n    for epoch in range(epochs):\n        model.train()\n        model.zero_grad()\n        start_time = time.time()\n\n        avg_loss = 0\n        avg_metric = []\n        for i, data in enumerate(train_loader):\n            \n            \n            optimizer.zero_grad()\n            #transforemer ________________________________-\n            inps = data['input'].to(device) # Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð±Ð°Ñ‚Ñ‡ Ð±Ñ‹Ð» Ð² ÐºÐ¾Ð½Ñ†Ðµ\n            ps = data['p'].unsqueeze(2).to(device) # Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð±Ð°Ñ‚Ñ‡ Ð±Ñ‹Ð» Ð² ÐºÐ¾Ð½Ñ†Ðµ\n\n            ps_input = ps[:, :-1]\n            \n            \n            (inps_mask, ps_input_mask, \n            inps_padding_mask, ps_input_padding_mask) = create_mask(inps.reshape(80, 64, 4), \n                                                                    ps_input.reshape(79, 64, 1))\n            pred = model(inps, ps_input, inps_mask, ps_input_mask,\n                           inps_padding_mask, ps_input_padding_mask, inps_padding_mask)\n\n            #transforemer ________________________________-\n            \n#             pred = model(data['input'].to(device)).squeeze(-1)\n\n            loss = criterion(\n                pred,\n                ps\n            )\n            metric = mean_absolute_error(data['p'], pred.detach().to('cpu').numpy())\n            avg_metric.append(metric)\n            loss.backward()\n            avg_loss += loss.item() / len(train_loader)\n            if not (i+1) % 10:\n                print(f'Metriccc: {np.mean(avg_metric)};')\n            \n            optimizer.step()\n\n        model.eval()\n        mae, avg_val_loss = 0, 0\n        preds = []\n\n        with torch.no_grad():\n            for data in val_loader:\n                pred = model(data['input'].to(device)).squeeze(-1)\n\n                loss = criterion(\n                    pred.detach(), \n                    data['p'].to(device)\n                )\n                avg_val_loss += loss.item() / len(val_loader)\n\n                preds.append(pred.detach().cpu().numpy())\n        \n        preds = np.concatenate(preds, 0).flatten()\n#         print(preds.shape, np.array(val_dataset.df['pressure'].values.tolist()).flatten().shape)\n        mae = mean_absolute_error(np.array(val_dataset.df['pressure'].values.tolist()).flatten(), preds)\n\n        elapsed_time = time.time() - start_time\n        if (epoch + 1) % verbose == 0:\n            elapsed_time = elapsed_time * verbose\n#             lr = scheduler.get_last_lr()[0]\n            print(\n                f\"Epoch {epoch + 1:02d}/{epochs:02d} \\t t={elapsed_time:.0f}s \\t\"\n                f\"loss={avg_loss:.3f}\",\n                f\"metric={np.mean(avg_metric):.3f}\",\n                end=\"\\t\",\n            )\n\n            if (epoch + 1 >= first_epoch_eval) or (epoch + 1 == epochs):\n                print(f\"val_loss={avg_val_loss:.3f}\\tmae={mae:.3f}\")\n            else:\n                print(\"\")\n\n    del (val_loader, train_loader, loss, data, pred)\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    return preds\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-24T16:30:06.613146Z","iopub.execute_input":"2021-09-24T16:30:06.613427Z","iopub.status.idle":"2021-09-24T16:30:06.637082Z","shell.execute_reply.started":"2021-09-24T16:30:06.613396Z","shell.execute_reply":"2021-09-24T16:30:06.636254Z"},"trusted":true},"execution_count":314,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict","metadata":{}},{"cell_type":"code","source":"def predict(\n    model,\n    dataset,\n    batch_size=64,\n    device=\"cuda\"\n):\n    \"\"\"\n    Usual torch predict function. Supports sigmoid and softmax activations.\n    Args:\n        model (torch model): Model to predict with.\n        dataset (PathologyDataset): Dataset to predict on.\n        batch_size (int, optional): Batch size. Defaults to 64.\n        device (str, optional): Device for torch. Defaults to \"cuda\".\n\n    Returns:\n        numpy array [len(dataset) x num_classes]: Predictions.\n    \"\"\"\n    model.eval()\n\n    loader = DataLoader(\n        dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS\n    )\n    \n    preds = []\n    with torch.no_grad():\n        for data in loader:\n            pred = model(data['input'].to(device)).squeeze(-1)\n            preds.append(pred.detach().cpu().numpy())\n\n    preds = np.concatenate(preds, 0)\n    return preds","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-24T15:34:45.438360Z","iopub.execute_input":"2021-09-24T15:34:45.438954Z","iopub.status.idle":"2021-09-24T15:34:45.445639Z","shell.execute_reply.started":"2021-09-24T15:34:45.438905Z","shell.execute_reply":"2021-09-24T15:34:45.444645Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(config, df_train, df_val, df_test, fold):\n    \"\"\"\n    Trains and validate a model.\n\n    Args:\n        config (Config): Parameters.\n        df_train (pandas dataframe): Training metadata.\n        df_val (pandas dataframe): Validation metadata.\n        df_test (pandas dataframe): Test metadata.\n        fold (int): Selected fold.\n\n    Returns:\n        np array: Study validation predictions.\n    \"\"\"\n\n    seed_everything(config.seed)\n\n#     model = RNNModel(\n#         input_dim=config.input_dim,\n#         lstm_dim=config.lstm_dim,\n#         dense_dim=config.dense_dim,\n#         logit_dim=config.logit_dim,\n#         num_classes=config.num_classes,\n#     ).to(config.device)\n#     model.zero_grad()abs\n\n    NHEAD = 8\n    FFN_HID_DIM = 128\n    NUM_ENCODER_LAYERS = 2\n    NUM_DECODER_LAYERS = 2\n    EMB_SIZE = 32\n\n    transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n                                     NHEAD, FFN_HID_DIM)\n\n    for p in transformer.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform_(p)\n\n    transformer = transformer.to(DEVICE)\n\n    train_dataset = VentilatorDataset(df_train)\n    val_dataset = VentilatorDataset(df_val)\n    test_dataset = VentilatorDataset(df_test)\n\n    n_parameters = count_parameters(transformer)\n\n    print(f\"    -> {len(train_dataset)} training breathes\")\n    print(f\"    -> {len(val_dataset)} validation breathes\")\n    print(f\"    -> {n_parameters} trainable parameters\\n\")\n\n    pred_val = fit(\n        transformer,\n        train_dataset,\n        val_dataset,\n        loss_name=config.loss,\n        optimizer=config.optimizer,\n        epochs=config.epochs,\n        batch_size=config.batch_size,\n        val_bs=config.val_bs,\n        lr=config.lr,\n        warmup_prop=config.warmup_prop,\n        verbose=config.verbose,\n        first_epoch_eval=config.first_epoch_eval,\n        device=config.device,\n    )\n    \n    pred_test = predict(\n        model, \n        test_dataset, \n        batch_size=config.val_bs, \n        device=config.device\n    )\n\n    if config.save_weights:\n        save_model_weights(\n            model,\n            f\"{config.selected_model}_{fold}.pt\",\n            cp_folder=\"\",\n        )\n\n    del (model, train_dataset, val_dataset, test_dataset)\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    return pred_val, pred_test","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-24T15:52:18.363111Z","iopub.execute_input":"2021-09-24T15:52:18.363423Z","iopub.status.idle":"2021-09-24T15:52:18.376328Z","shell.execute_reply.started":"2021-09-24T15:52:18.363392Z","shell.execute_reply":"2021-09-24T15:52:18.375608Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"markdown","source":"### $k$-fold","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\n\ndef k_fold(config, df, df_test):\n    \"\"\"\n    Performs a patient grouped k-fold cross validation.\n    \"\"\"\n\n    pred_oof = np.zeros(len(df))\n    preds_test = []\n    \n    gkf = GroupKFold(n_splits=config.k)\n    splits = list(gkf.split(X=df, y=df, groups=df[\"breath_id\"]))\n\n    for i, (train_idx, val_idx) in enumerate(splits):\n        if i in config.selected_folds:\n            print(f\"\\n-------------   Fold {i + 1} / {config.k}  -------------\\n\")\n\n            df_train = df.iloc[train_idx].copy().reset_index(drop=True)\n            df_val = df.iloc[val_idx].copy().reset_index(drop=True)\n#             return train(config, df_train, df_val, df_test, i)\n            pred_val, pred_test = train(config, df_train, df_val, df_test, i)\n            \n            pred_oof[val_idx] = pred_val.flatten()\n            preds_test.append(pred_test.flatten())\n\n#     print(f'\\n -> CV MAE : {compute_metric(df, pred_oof) :.3f}')\n\n    return pred_oof, np.mean(preds_test, 0)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-24T15:52:19.212482Z","iopub.execute_input":"2021-09-24T15:52:19.212739Z","iopub.status.idle":"2021-09-24T15:52:19.222879Z","shell.execute_reply.started":"2021-09-24T15:52:19.212710Z","shell.execute_reply":"2021-09-24T15:52:19.222138Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"class Config:\n    \"\"\"\n    Parameters used for training\n    \"\"\"\n    # General\n    seed = 42\n    verbose = 1\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    save_weights = True\n\n    # k-fold\n    k = 5\n    selected_folds = [0, 1, 2, 3, 4]\n    \n    # Model\n    selected_model = 'rnn'\n    input_dim = 4\n\n    dense_dim = 32\n    lstm_dim = 256\n    logit_dim = 32\n    num_classes = 1\n\n    # Training\n    loss = \"L1Loss\"  # not used\n    optimizer = \"Adam\"\n    batch_size = 64\n    epochs = 150\n\n    lr = 1e-3\n    warmup_prop = 0\n\n    val_bs = 64\n    first_epoch_eval = 0","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:52:20.203758Z","iopub.execute_input":"2021-09-24T15:52:20.204054Z","iopub.status.idle":"2021-09-24T15:52:20.210848Z","shell.execute_reply.started":"2021-09-24T15:52:20.204018Z","shell.execute_reply":"2021-09-24T15:52:20.209711Z"},"trusted":true},"execution_count":230,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.array(dataset.df['pressure'].values.tolist()).flatten()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:52:21.003478Z","iopub.execute_input":"2021-09-24T15:52:21.004242Z","iopub.status.idle":"2021-09-24T15:52:21.008213Z","shell.execute_reply.started":"2021-09-24T15:52:21.004203Z","shell.execute_reply":"2021-09-24T15:52:21.007180Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"# a = k_fold(\n#     Config, \n#     df_train,\n#     df_test,\n# )","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:52:21.223364Z","iopub.execute_input":"2021-09-24T15:52:21.223884Z","iopub.status.idle":"2021-09-24T15:52:21.227482Z","shell.execute_reply.started":"2021-09-24T15:52:21.223849Z","shell.execute_reply":"2021-09-24T15:52:21.226516Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"code","source":"# a['p'].unsqueeze(2).T[:, :-1].size()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:52:21.941515Z","iopub.execute_input":"2021-09-24T15:52:21.942047Z","iopub.status.idle":"2021-09-24T15:52:21.945871Z","shell.execute_reply.started":"2021-09-24T15:52:21.942014Z","shell.execute_reply":"2021-09-24T15:52:21.944874Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"pred_oof, pred_test = k_fold(\n    Config, \n    df_train,\n    df_test,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T16:30:11.604574Z","iopub.execute_input":"2021-09-24T16:30:11.605068Z","iopub.status.idle":"2021-09-24T16:30:29.530345Z","shell.execute_reply.started":"2021-09-24T16:30:11.605028Z","shell.execute_reply":"2021-09-24T16:30:29.528254Z"},"trusted":true},"execution_count":315,"outputs":[]},{"cell_type":"code","source":"torch.Tensor([[1,2,3], [1,2,4]]).unsqueeze(2)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T14:42:38.155471Z","iopub.execute_input":"2021-09-24T14:42:38.156071Z","iopub.status.idle":"2021-09-24T14:42:38.166417Z","shell.execute_reply.started":"2021-09-24T14:42:38.156031Z","shell.execute_reply":"2021-09-24T14:42:38.165665Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### Predictions","metadata":{}},{"cell_type":"code","source":"def plot_prediction(sample_id, df):\n    df_breath = df[df['breath_id'] == sample_id]\n\n    cols = ['u_in', 'u_out', 'pressure'] if 'pressure' in df.columns else ['u_in', 'u_out']\n    \n    plt.figure(figsize=(12, 4))\n    for col in ['pred', 'pressure', 'u_out']:\n        plt.plot(df_breath['time_step'], df_breath[col], label=col)\n        \n    metric = compute_metric(df_breath, df_breath['pred'])\n        \n    plt.legend()\n    plt.title(f'Sample {sample_id} - MAE={metric:.3f}')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-24T11:06:57.497868Z","iopub.status.idle":"2021-09-24T11:06:57.498158Z","shell.execute_reply.started":"2021-09-24T11:06:57.498005Z","shell.execute_reply":"2021-09-24T11:06:57.498025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"pred\"] = pred_oof","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:17:15.938676Z","iopub.execute_input":"2021-09-23T17:17:15.938871Z","iopub.status.idle":"2021-09-23T17:17:15.95552Z","shell.execute_reply.started":"2021-09-23T17:17:15.938849Z","shell.execute_reply":"2021-09-23T17:17:15.954869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df_train['breath_id'].unique()[:5]:\n    plot_prediction(i, df_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:17:16.185855Z","iopub.execute_input":"2021-09-23T17:17:16.186326Z","iopub.status.idle":"2021-09-23T17:17:17.441182Z","shell.execute_reply.started":"2021-09-23T17:17:16.186296Z","shell.execute_reply":"2021-09-23T17:17:17.44052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sub","metadata":{}},{"cell_type":"code","source":"df_test['pred'] = pred_test\n\nfor i in df_test['breath_id'].unique()[:5]:\n    plot_prediction(i, df_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:17:17.442649Z","iopub.execute_input":"2021-09-23T17:17:17.442984Z","iopub.status.idle":"2021-09-23T17:17:18.576097Z","shell.execute_reply.started":"2021-09-23T17:17:17.442946Z","shell.execute_reply":"2021-09-23T17:17:18.57542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['pressure'] = pred_test\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:17:18.577658Z","iopub.execute_input":"2021-09-23T17:17:18.577993Z","iopub.status.idle":"2021-09-23T17:17:29.055813Z","shell.execute_reply.started":"2021-09-23T17:17:18.577955Z","shell.execute_reply":"2021-09-23T17:17:29.055029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Thanks for reading !**","metadata":{}}]}